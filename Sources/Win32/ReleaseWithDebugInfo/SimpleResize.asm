; Listing generated by Microsoft (R) Optimizing Compiler Version 19.00.24215.1 

	TITLE	c:\github\mvtools\sources\simpleresize.cpp
	.686P
	.XMM
	include listing.inc
	.model	flat

INCLUDELIB OLDNAMES

PUBLIC	??$SimpleResizeDo_New@F@SimpleResize@@QAEXPAEHHHPBEHH@Z ; SimpleResize::SimpleResizeDo_New<short>
PUBLIC	??$SimpleResizeDo_New@E@SimpleResize@@QAEXPAEHHHPBEHH@Z ; SimpleResize::SimpleResizeDo_New<unsigned char>
PUBLIC	?InitTables@SimpleResize@@AAEXXZ		; SimpleResize::InitTables
PUBLIC	?SimpleResizeDo_uint16@SimpleResize@@QAEXPAFHHHPBFHH@Z ; SimpleResize::SimpleResizeDo_uint16
PUBLIC	?SimpleResizeDo_uint8@SimpleResize@@QAEXPAEHHHPBEHHH@Z ; SimpleResize::SimpleResizeDo_uint8
PUBLIC	??1SimpleResize@@QAE@XZ				; SimpleResize::~SimpleResize
PUBLIC	??0SimpleResize@@QAE@HHHHJ@Z			; SimpleResize::SimpleResize
; Function compile flags: /Ogtpy
; File c:\github\mvtools\sources\simpleresize.cpp
;	COMDAT ??0SimpleResize@@QAE@HHHHJ@Z
_TEXT	SEGMENT
__newwidth$ = 8						; size = 4
__newheight$ = 12					; size = 4
__oldwidth$ = 16					; size = 4
__oldheight$ = 20					; size = 4
_CPUFlags$ = 24						; size = 4
??0SimpleResize@@QAE@HHHHJ@Z PROC			; SimpleResize::SimpleResize, COMDAT
; _this$ = ecx

; 78   :   oldwidth = _oldwidth;

	mov	eax, DWORD PTR __oldwidth$[esp-4]

; 79   :   oldheight = _oldheight;
; 80   :   newwidth = _newwidth;

	mov	edx, DWORD PTR __newwidth$[esp-4]
	push	esi

; 81   :   newheight = _newheight;
; 82   :   SSE2enabled = (CPUFlags & CPUF_SSE2) != 0;
; 83   : //  SSEMMXenabled = (CPUFlags& CPUF_INTEGER_SSE) != 0;
; 84   : 
; 85   :   // 2 qwords, 2 offsets, and prefetch slack
; 86   :   hControl = (unsigned int*)_aligned_malloc(newwidth * 12 + 128, 128);   // aligned for P4 cache line

	mov	esi, DWORD PTR __imp___aligned_malloc
	push	edi
	mov	edi, ecx
	push	128					; 00000080H
	mov	DWORD PTR [edi+8], eax
	mov	eax, DWORD PTR __oldheight$[esp+8]
	mov	DWORD PTR [edi+12], eax
	mov	eax, DWORD PTR __newheight$[esp+8]
	mov	DWORD PTR [edi+4], eax
	mov	eax, DWORD PTR _CPUFlags$[esp+8]
	shr	eax, 5
	and	al, 1
	mov	DWORD PTR [edi], edx
	mov	BYTE PTR [edi+36], al
	lea	eax, DWORD PTR [edx+edx*2]
	lea	eax, DWORD PTR [eax*4+128]
	push	eax
	call	esi
	mov	DWORD PTR [edi+16], eax

; 87   :   vWorkY = (unsigned char*)_aligned_malloc(2 * oldwidth + 128, 128); // for unsigned char type resize

	mov	eax, DWORD PTR [edi+8]
	push	128					; 00000080H
	lea	eax, DWORD PTR [eax*2+128]
	push	eax
	call	esi
	mov	DWORD PTR [edi+28], eax

; 88   :   vOffsets = (unsigned int*)_aligned_malloc(newheight * 4, 128);

	mov	eax, DWORD PTR [edi+4]
	shl	eax, 2
	push	128					; 00000080H
	push	eax
	call	esi
	mov	DWORD PTR [edi+20], eax

; 89   :   vWeights = (unsigned int*)_aligned_malloc(newheight * 4, 128);

	mov	eax, DWORD PTR [edi+4]
	shl	eax, 2
	push	128					; 00000080H
	push	eax
	call	esi
	mov	DWORD PTR [edi+24], eax

; 90   : 
; 91   :   vWorkY2 = (short*)_aligned_malloc(2 * oldwidth + 128, 128); // for short type resize

	mov	eax, DWORD PTR [edi+8]
	push	128					; 00000080H
	lea	eax, DWORD PTR [eax*2+128]
	push	eax
	call	esi
	add	esp, 40					; 00000028H
	mov	DWORD PTR [edi+32], eax

; 92   : 
; 93   :   //		if (!hControl || !vWeights)
; 94   :   {
; 95   :     //			env->ThrowError("SimpleResize: memory allocation error");
; 96   :   }
; 97   : 
; 98   :   InitTables();

	mov	ecx, edi
	call	?InitTables@SimpleResize@@AAEXXZ	; SimpleResize::InitTables

; 99   : };

	mov	eax, edi
	pop	edi
	pop	esi
	ret	20					; 00000014H
??0SimpleResize@@QAE@HHHHJ@Z ENDP			; SimpleResize::SimpleResize
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File c:\github\mvtools\sources\simpleresize.cpp
;	COMDAT ??1SimpleResize@@QAE@XZ
_TEXT	SEGMENT
??1SimpleResize@@QAE@XZ PROC				; SimpleResize::~SimpleResize, COMDAT
; _this$ = ecx

; 102  : {

	push	esi

; 103  :   _aligned_free(hControl);

	mov	esi, DWORD PTR __imp___aligned_free
	push	edi
	mov	edi, ecx
	push	DWORD PTR [edi+16]
	call	esi

; 104  :   _aligned_free(vWorkY);

	push	DWORD PTR [edi+28]
	call	esi

; 105  :   _aligned_free(vWorkY2);

	push	DWORD PTR [edi+32]
	call	esi

; 106  :   _aligned_free(vOffsets);

	push	DWORD PTR [edi+20]
	call	esi

; 107  :   _aligned_free(vWeights);

	push	DWORD PTR [edi+24]
	call	esi
	add	esp, 20					; 00000014H
	pop	edi
	pop	esi

; 108  : }

	ret	0
??1SimpleResize@@QAE@XZ ENDP				; SimpleResize::~SimpleResize
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File c:\github\mvtools\sources\simpleresize.cpp
;	COMDAT ?SimpleResizeDo_uint8@SimpleResize@@QAEXPAEHHHPBEHHH@Z
_TEXT	SEGMENT
_y$1$ = -28						; size = 4
_vOffsetsW$1$ = -24					; size = 4
_vWorkYW$1$ = -20					; size = 4
tv701 = -16						; size = 4
_CurrentWeight$1$ = -12					; size = 4
_pControl$1$ = -8					; size = 4
_vWeightsW$1$ = -4					; size = 4
_dstp$1$ = 8						; size = 4
_dstp$ = 8						; size = 4
_row_size$ = 12						; size = 4
_height$ = 16						; size = 4
_dst_pitch$ = 20					; size = 4
_srcp$ = 24						; size = 4
_src_row_size$ = 28					; size = 4
_src_pitch$ = 32					; size = 4
_Planar_Type$dead$ = 36					; size = 4
?SimpleResizeDo_uint8@SimpleResize@@QAEXPAEHHHPBEHHH@Z PROC ; SimpleResize::SimpleResizeDo_uint8, COMDAT
; _this$ = ecx

; 364  : {

	sub	esp, 28					; 0000001cH

; 365  :   // Note: PlanarType is dummy, I (Fizick) do not use croma planes code for resize in MVTools
; 366  : /* test:
; 367  : SetMemoryMax(6000)
; 368  : a=Avisource("c:\tape13\Videos\Tape02_digitall_Hi8.avi").assumefps(25,1).trim(0, 499)
; 369  : a=a.AssumeBFF()
; 370  : a=a.QTGMC(Preset="Slower",dct=5, ChromaMotion=true)
; 371  : sup = a.MSuper(pel=1)
; 372  : fw = sup.MAnalyse(isb=false, delta=1, overlap=4)
; 373  : bw = sup.MAnalyse(isb=true, delta=1, overlap=4)
; 374  : a=a.MFlowInter(sup, bw, fw, time=50, thSCD1=400) # MFlowInter uses SimpleResize
; 375  : a
; 376  : */
; 377  : 
; 378  :   bool use_c = false;
; 379  : #ifndef OLD_ASM
; 380  :   if (SSE2enabled) {

	cmp	BYTE PTR [ecx+36], 0
	je	SHORT $LN11@SimpleResi

; 381  :     SimpleResizeDo_New<uint8_t>(dstp, row_size, height, dst_pitch, srcp, src_row_size, src_pitch);

	push	DWORD PTR _src_pitch$[esp+24]
	push	DWORD PTR _src_row_size$[esp+28]
	push	DWORD PTR _srcp$[esp+32]
	push	DWORD PTR _dst_pitch$[esp+36]
	push	DWORD PTR _height$[esp+40]
	push	DWORD PTR _row_size$[esp+44]
	push	DWORD PTR _dstp$[esp+48]
	call	??$SimpleResizeDo_New@E@SimpleResize@@QAEXPAEHHHPBEHH@Z ; SimpleResize::SimpleResizeDo_New<unsigned char>

; 824  :   }
; 825  : 
; 826  : }

	add	esp, 28					; 0000001cH
	ret	32					; 00000020H
$LN11@SimpleResi:

; 382  :     return;
; 383  :   }
; 384  : #endif
; 385  :   use_c = true; 
; 386  :   typedef unsigned char src_type;
; 387  :   // later for the other SimpleResizeDo for vectors this is unsigned short
; 388  :   // typedef short src_type; 
; 389  : 
; 390  :   typedef src_type workY_type; // be the same
; 391  : 
; 392  : #ifdef OLD_ASM
; 393  :   int vWeight1[4];
; 394  :   int vWeight2[4];
; 395  :   // not needed for short
; 396  :   const __int64 FPround1[2] = { 0x0080008000800080,0x0080008000800080 }; // round words
; 397  :                                                                          // needed for byte and short
; 398  :   const __int64 FPround2[2] = { 0x0000008000000080,0x0000008000000080 };// round dwords
; 399  :                                                                         // not needed for short
; 400  :   const __int64 FPround4 = 0x0080008000800080;// round words
; 401  : #endif
; 402  : 
; 403  :   const unsigned int* pControl = &hControl[0];

	mov	eax, DWORD PTR [ecx+16]

; 404  : 
; 405  :   const src_type * srcp1;
; 406  :   const src_type * srcp2;
; 407  :   workY_type * vWorkYW = sizeof(workY_type) == 1 ? (workY_type *)vWorkY : (workY_type *)vWorkY2;
; 408  : 
; 409  :   unsigned int* vOffsetsW = vOffsets;

	mov	edx, DWORD PTR [ecx+20]
	push	ebx
	mov	ebx, DWORD PTR [ecx+28]
	push	esi

; 410  :   unsigned int* vWeightsW = vWeights;

	mov	esi, DWORD PTR [ecx+24]

; 411  : 
; 412  : #ifdef OLD_ASM
; 413  :   bool	SSE2enabledW = SSE2enabled;		// in local storage for asm
; 414  :   bool	SSEMMXenabledW = SSEMMXenabled;		// in local storage for asm
; 415  : #endif
; 416  :   // Just in case things are not aligned right, maybe turn off sse2
; 417  : 
; 418  :   for (int y = 0; y < height; y++)

	xor	ecx, ecx
	mov	DWORD PTR _pControl$1$[esp+36], eax
	mov	eax, DWORD PTR _height$[esp+32]
	mov	DWORD PTR _vWorkYW$1$[esp+36], ebx
	mov	DWORD PTR _vOffsetsW$1$[esp+36], edx
	mov	DWORD PTR _y$1$[esp+36], ecx
	test	eax, eax
	jle	$LN32@SimpleResi
	push	ebp
	dec	eax
	sub	esi, edx
	push	edi
	mov	edi, DWORD PTR _dstp$[esp+40]
	mov	DWORD PTR tv701[esp+44], eax
	mov	DWORD PTR _vWeightsW$1$[esp+44], esi
	mov	DWORD PTR _dstp$1$[esp+40], edi
$LL4@SimpleResi:

; 419  :   {
; 420  :     int CurrentWeight = vWeightsW[y];

	mov	eax, DWORD PTR [esi+edx]

; 421  :     int invCurrentWeight = 256 - CurrentWeight;

	mov	ebp, 256				; 00000100H

; 422  : 
; 423  : #ifdef OLD_ASM
; 424  :     // fill 4x(16x2) bit for inline asm 
; 425  :     // for intrinsic it is not needed anymore
; 426  :     vWeight1[0] = vWeight1[1] = vWeight1[2] = vWeight1[3] =
; 427  :       (invCurrentWeight << 16) | invCurrentWeight;
; 428  : 
; 429  :     vWeight2[0] = vWeight2[1] = vWeight2[2] = vWeight2[3] =
; 430  :       (CurrentWeight << 16) | CurrentWeight;
; 431  : #endif
; 432  :     srcp1 = srcp + vOffsetsW[y] * src_pitch;

	mov	esi, DWORD PTR [edx]
	sub	ebp, eax
	mov	DWORD PTR _CurrentWeight$1$[esp+44], eax
	mov	eax, DWORD PTR _src_pitch$[esp+40]
	imul	esi, eax
	add	esi, DWORD PTR _srcp$[esp+40]
	cmp	ecx, DWORD PTR tv701[esp+44]
	lea	edx, DWORD PTR [esi+eax]

; 433  : 
; 434  :     // scrp2 is the next line (check for the most bottom line)
; 435  :     srcp2 = (y < height - 1) ? srcp1 + src_pitch : srcp1;
; 436  : 
; 437  :     if (use_c) // always C here
; 438  :     {
; 439  :       // recovered (and commented) C version as sort of doc
; 440  :       for (int x = 0; x < src_row_size; x++) {

	mov	eax, DWORD PTR _src_row_size$[esp+40]
	cmovge	edx, esi
	test	eax, eax
	jle	SHORT $LN6@SimpleResi
	sub	esi, edx
	mov	edi, eax
	sub	ebx, edx
$LL7@SimpleResi:

; 441  :         vWorkYW[x] = (srcp1[x] * invCurrentWeight + srcp2[x] * CurrentWeight + 128) >> 8;

	movzx	eax, BYTE PTR [edx]
	lea	edx, DWORD PTR [edx+1]
	imul	eax, DWORD PTR _CurrentWeight$1$[esp+44]
	movzx	ecx, BYTE PTR [esi+edx-1]
	imul	ecx, ebp
	sub	eax, -128				; ffffff80H
	add	eax, ecx
	sar	eax, 8
	mov	BYTE PTR [ebx+edx-1], al
	sub	edi, 1
	jne	SHORT $LL7@SimpleResi
	mov	edi, DWORD PTR _dstp$1$[esp+40]
	mov	ecx, DWORD PTR _y$1$[esp+44]
$LN6@SimpleResi:

; 442  :       }
; 443  :       // We've taken care of the vertical scaling, now do horizontal
; 444  :       for (int x = 0; x < row_size; x++) {

	xor	ebx, ebx
	cmp	DWORD PTR _row_size$[esp+40], ebx
	jle	SHORT $LN9@SimpleResi
	mov	eax, DWORD PTR _pControl$1$[esp+44]
	mov	ebp, DWORD PTR _vWorkYW$1$[esp+44]
	add	eax, -8					; fffffff8H
$LL10@SimpleResi:

; 445  :         unsigned int pc;
; 446  :         unsigned int offs;
; 447  : 
; 448  :         // eax: get data offset in pixels, 1st pixel pair. Control[4]=offs
; 449  :         if ((x & 1) == 0) { // even

	test	bl, 1
	jne	SHORT $LN13@SimpleResi

; 450  :           pc = pControl[3 * x];

	mov	esi, DWORD PTR [eax+8]

; 451  :           offs = pControl[3 * x + 4];

	mov	edi, DWORD PTR [eax+24]

; 452  :         }
; 453  :         else { // odd

	jmp	SHORT $LN14@SimpleResi
$LN13@SimpleResi:

; 454  :           pc = pControl[3 * x - 2]; // [3*xeven+1]

	mov	esi, DWORD PTR [eax]

; 455  :           offs = pControl[3 * x + 2]; // [3*xeven+5]

	mov	edi, DWORD PTR [eax+16]
$LN14@SimpleResi:

; 456  :         }
; 457  :         unsigned int wY1 = pc & 0x0000ffff; //low
; 458  :         unsigned int wY2 = pc >> 16; //high
; 459  :         dstp[x] = (vWorkYW[offs] * wY1 + vWorkYW[offs + 1] * wY2 + 128) >> 8;

	movzx	edx, BYTE PTR [edi+ebp+1]
	mov	ecx, esi
	shr	ecx, 16					; 00000010H
	add	eax, 12					; 0000000cH
	imul	edx, ecx
	movzx	ecx, BYTE PTR [edi+ebp]
	mov	edi, DWORD PTR _dstp$1$[esp+40]
	imul	ecx, esi
	sub	ecx, -128				; ffffff80H
	add	ecx, edx
	shr	ecx, 8
	mov	BYTE PTR [ebx+edi], cl
	inc	ebx
	cmp	ebx, DWORD PTR _row_size$[esp+40]
	jl	SHORT $LL10@SimpleResi
	mov	ecx, DWORD PTR _y$1$[esp+44]
$LN9@SimpleResi:

; 411  : 
; 412  : #ifdef OLD_ASM
; 413  :   bool	SSE2enabledW = SSE2enabled;		// in local storage for asm
; 414  :   bool	SSEMMXenabledW = SSEMMXenabled;		// in local storage for asm
; 415  : #endif
; 416  :   // Just in case things are not aligned right, maybe turn off sse2
; 417  : 
; 418  :   for (int y = 0; y < height; y++)

	mov	edx, DWORD PTR _vOffsetsW$1$[esp+44]
	inc	ecx

; 460  :       }
; 461  : 
; 462  : 
; 463  :     }
; 464  : #ifdef OLD_ASM
; 465  :     // inline asm ignored 
; 466  :     else {
; 467  :       // Do Vertical. First SSE2 (mod16) then MMX (mod8) then MMX (for last_pos-8)
; 468  :       // This one already ported to intrinsics (SSE2 mod16) + rest C
; 469  :       _asm
; 470  :       {
; 471  :         //emms // added by paranoid Fizick
; 472  :         //push	ecx						// have to save this? Intel2017:should be commented out
; 473  :         mov		ecx, src_row_size
; 474  :         shr		ecx, 3					// 8 bytes a time
; 475  :         mov		rsi, srcp1				// top of 2 src lines to get
; 476  :         mov		rdx, srcp2				// next "
; 477  :         mov		rdi, vWorkYW			// luma work destination line
; 478  :         xor		rax, rax                // P.F. 16.04.28 should be rax here not eax (hack! define rax as eax in 32 bit) eax/rax is an indexer 
; 479  :         xor   rbx, rbx                // P.F. 16.04.28 later we use only EBX but index with RBX
; 480  : 
; 481  :         // Let's check here to see if we are on a P4 or higher and can use SSE2 instructions.
; 482  :         // This first loop is not the performance bottleneck anyway but it is trivial to tune
; 483  :         // using SSE2 if we have proper alignment.
; 484  : 
; 485  :         test    SSE2enabledW, 1			// is SSE2 supported?
; 486  :         jz		vMaybeSSEMMX				// n, can't do anyway
; 487  : 
; 488  : // if src_row_size < 16 jump to vMaybeSSEMMX
; 489  : cmp     ecx, 2					// we have at least 16 byts, 2 qwords?
; 490  : jl		vMaybeSSEMMX				// n, don't bother
; 491  : // srcp1 and srcp2 should be 16 byte aligned else jump to vMaybeSSEMMX
; 492  : mov		rbx, rsi
; 493  : or rbx, rdx
; 494  : test    rbx, 0xf				// both src rows 16 byte aligned?
; 495  : jnz		vMaybeSSEMMX			// n, don't use sse2
; 496  : // SSE2 part from here
; 497  : shr		ecx, 1					// do 16 bytes at a time instead. ecx now src_row_size/16
; 498  : dec		ecx						// jigger loop ct
; 499  : align	16
; 500  : movdqu  xmm0, FPround1 // { 0x0080008000800080,0x0080008000800080 }; // round words _mm_set1_epi16(0x0080)
; 501  : movdqu	xmm5, vWeight1  // __m128i weight1_xmm5 = _mm_loadu_si128(vWeight1)
; 502  : movdqu	xmm6, vWeight2  // __m128i weight2_xmm6 = _mm_loadu_si128(vWeight2)
; 503  : pxor	xmm7, xmm7        // __m128i zero = _mm_setzero_si128()
; 504  : 
; 505  : align   16
; 506  : vLoopSSE2_Fetch:
; 507  :         prefetcht0[rsi + rax * 2 + 16]
; 508  :           prefetcht0[rdx + rax * 2 + 16]
; 509  : 
; 510  :           // move unaligned
; 511  :           vLoopSSE2 :
; 512  :           // __mm128i src_lo_xmm1 = _mm_loadu_si128(src1 + x_eax)
; 513  :           movdqu	xmm1, xmmword ptr[rsi + rax] // top of 2 lines to interpolate
; 514  :             // __mm128i src_hi_xmm3 = _mm_loadu_si128(src2 + x_eax)
; 515  :           movdqu	xmm3, xmmword ptr[rdx + rax] // 2nd of 2 lines
; 516  :             // xmm2 = xmm1
; 517  :             // xmm4 = xmm3
; 518  :           movdqa  xmm2, xmm1
; 519  :           movdqa  xmm4, xmm3
; 520  :             // xmm1 = _mm_unpacklo_epi8(xmm1, zero)
; 521  :             // xmm2 = _mm_unpackhi_epi8(xmm2, zero)
; 522  :           punpcklbw xmm1, xmm7			// make words
; 523  :           punpckhbw xmm2, xmm7			// "
; 524  :             // xmm3 = _mm_unpacklo_epi8(xmm3, zero)
; 525  :             // xmm4 = _mm_unpackhi_epi8(xmm4, zero)
; 526  :           punpcklbw xmm3, xmm7			// "
; 527  :           punpckhbw xmm4, xmm7			// "
; 528  : 
; 529  :             // xmm1 = _mm_mullo_epi16(xmm1, weight1_xmm5) // mult by weighting factor 1
; 530  :             // xmm2 = _mm_mullo_epi16(xmm2, weight1_xmm5)
; 531  :           pmullw	xmm1, xmm5				// mult by top weighting factor
; 532  :           pmullw	xmm2, xmm5              // "
; 533  :           // xmm3 = _mm_mullo_epi16(xmm3, weight2_xmm6) // mult by weighting factor 2
; 534  :           // xmm4 = _mm_mullo_epi16(xmm4, weight2_xmm6)
; 535  :           pmullw	xmm3, xmm6				// mult by bot weighting factor
; 536  :           pmullw	xmm4, xmm6              // "
; 537  :             // xmm1 = _mm_add_epi16(xmm1,xmm3) // combine lumas low
; 538  :           paddw	xmm1, xmm3				// combine lumas low
; 539  :             // xmm2 = _mm_add_epi16(xmm2,xmm4) // combine lumas high
; 540  :           paddw	xmm2, xmm4				// combine lumas high
; 541  :             // xmm1 = _mm_adds_epu16(xmm1, round_xmm0)
; 542  :             // xmm2 = _mm_adds_epu16(xmm2, round_xmm0)
; 543  :           paddusw	xmm1, xmm0				// round
; 544  :           paddusw	xmm2, xmm0				// round
; 545  :             // xmm1 = _mm_srli_epi16(xmm1, 8) // right adjust luma
; 546  :             // xmm2 = _mm_srli_epi16(xmm2, 8)
; 547  :           psrlw	xmm1, 8					// right adjust luma
; 548  :           psrlw	xmm2, 8					// right adjust luma
; 549  :             // xmm1 = _mm_packus_epi16(xmm1, xmm2)
; 550  :           packuswb xmm1, xmm2				// pack words to our 16 byte answer
; 551  :             // _mm_stream_si128(vWorkYW+eax, xmm1) // movntdq don't pollute cache
; 552  :           movntdq	xmmword ptr[rdi + rax], xmm1	// save lumas in our work area
; 553  :             //x_eax+=16
; 554  :           lea     rax, [rax + 16]  // P.F. 16.04.28 ?should be rax here not eax (hack! define rax eax in 32 bit)
; 555  :           dec		ecx						// was: src_row_size/16 loop until zero
; 556  :           jg		vLoopSSE2_Fetch			// if not on last one loop, prefetch
; 557  :           jz		vLoopSSE2				// or just loop, or not
; 558  : 
; 559  :     // done with our SSE2 fortified loop but we may need to pick up the spare change
; 560  :           sfence
; 561  :           mov		ecx, src_row_size		// get count again
; 562  :           and		ecx, 0x0000000f			// just need mod 16
; 563  :           movq	mm5, vWeight1
; 564  :           movq	mm6, vWeight2
; 565  :           movq	mm0, FPround1			// useful rounding constant
; 566  :           shr		ecx, 3					// 8 bytes at a time, any?
; 567  :           jz		MoreSpareChange			// n, did them all		
; 568  : 
; 569  : 
; 570  :     // Let's check here to see if we are on a P2 or Athlon and can use SSEMMX instructions.
; 571  :     // This first loop is not the performance bottleneck anyway but it is trivial to tune
; 572  :     // using SSE if we have proper alignment.
; 573  :         vMaybeSSEMMX:
; 574  :         movq	mm5, vWeight1
; 575  :           movq	mm6, vWeight2
; 576  :           movq	mm0, FPround1			// useful rounding constant
; 577  :           pxor	mm7, mm7
; 578  :           test    SSEMMXenabledW, 1		// is SSE supported?
; 579  :           jz		vLoopMMX				// n, can't do anyway
; 580  :           dec     ecx						// jigger loop ctr
; 581  : 
; 582  :           align	16
; 583  :           vLoopSSEMMX_Fetch:
; 584  :         prefetcht0[rsi + rax + 8]
; 585  :           prefetcht0[rdx + rax + 8]
; 586  : 
; 587  :           vLoopSSEMMX :
; 588  :           movq	mm1, qword ptr[rsi + rax] // top of 2 lines to interpolate
; 589  :           movq	mm3, qword ptr[rdx + rax] // 2nd of 2 lines
; 590  :           movq	mm2, mm1				// copy top bytes
; 591  :           movq	mm4, mm3				// copy 2nd bytes
; 592  : 
; 593  :           punpcklbw mm1, mm7				// make words
; 594  :           punpckhbw mm2, mm7				// "
; 595  :           punpcklbw mm3, mm7				// "
; 596  :           punpckhbw mm4, mm7				// "
; 597  : 
; 598  :           pmullw	mm1, mm5				// mult by weighting factor
; 599  :           pmullw	mm2, mm5				// mult by weighting factor
; 600  :           pmullw	mm3, mm6				// mult by weighting factor
; 601  :           pmullw	mm4, mm6				// mult by weighting factor
; 602  : 
; 603  :           paddw	mm1, mm3				// combine lumas
; 604  :           paddw	mm2, mm4				// combine lumas
; 605  : 
; 606  :           paddusw	mm1, mm0				// round
; 607  :           paddusw	mm2, mm0				// round
; 608  : 
; 609  :           psrlw	mm1, 8					// right adjust luma
; 610  :           psrlw	mm2, 8					// right adjust luma
; 611  : 
; 612  :           packuswb mm1, mm2				// pack UV's into low dword
; 613  : 
; 614  :           movntq	qword ptr[rdi + rax], mm1	// save in our work area
; 615  : 
; 616  :           lea     rax, [rax + 8]      // P.F. 16.04.28 should be rax here not eax (hack! define rax eax in 32 bit)
; 617  :           dec		ecx
; 618  :           jg		vLoopSSEMMX_Fetch			// if not on last one loop, prefetch
; 619  :           jz		vLoopSSEMMX				// or just loop, or not
; 620  :           sfence
; 621  :           jmp		MoreSpareChange			// all done with vertical
; 622  : 
; 623  :           align	16
; 624  :           vLoopMMX:
; 625  :         movq	mm1, qword ptr[rsi + rax] // top of 2 lines to interpolate
; 626  :           movq	mm3, qword ptr[rdx + rax] // 2nd of 2 lines
; 627  :           movq	mm2, mm1				// copy top bytes
; 628  :           movq	mm4, mm3				// copy 2nd bytes
; 629  : 
; 630  :           punpcklbw mm1, mm7				// make words
; 631  :           punpckhbw mm2, mm7				// "
; 632  :           punpcklbw mm3, mm7				// "
; 633  :           punpckhbw mm4, mm7				// "
; 634  : 
; 635  :           pmullw	mm1, mm5				// mult by weighting factor
; 636  :           pmullw	mm2, mm5				// mult by weighting factor
; 637  :           pmullw	mm3, mm6				// mult by weighting factor
; 638  :           pmullw	mm4, mm6				// mult by weighting factor
; 639  : 
; 640  :           paddw	mm1, mm3				// combine lumas
; 641  :           paddw	mm2, mm4				// combine lumas
; 642  : 
; 643  :           paddusw	mm1, mm0				// round
; 644  :           paddusw	mm2, mm0				// round
; 645  : 
; 646  :           psrlw	mm1, 8					// right just 
; 647  :           psrlw	mm2, 8					// right just 
; 648  : 
; 649  :           packuswb mm1, mm2				// pack UV's into low dword
; 650  : 
; 651  :           movq	qword ptr[rdi + rax], mm1	// save lumas in our work area
; 652  : 
; 653  :           lea     rax, [rax + 8]            // P.F. 16.04.28 should be rax here not eax (hack! define rax eax in 32 bit)
; 654  :           loop	vLoopMMX
; 655  : 
; 656  :           // Trick!
; 657  :           // Add a little code here to check if we have more pixels to do and, if so, make one
; 658  :           // more pass thru vLoopMMX. We were processing in multiples of 8 pixels and alway have
; 659  :           // an even number so there will never be more than 7 left. 
; 660  :         MoreSpareChange:
; 661  :         cmp		eax, src_row_size		// EAX! did we get them all // P.F. 16.04.28 should be rax here not eax (hack! define rax eax in 32 bit)
; 662  :           jnl		DoHorizontal			// yes, else have 2 left
; 663  :           mov		ecx, 1					// jigger loop ct
; 664  :           mov		eax, src_row_size       // EAX! P.F. 16.04.28 should be rax here not eax (hack! define rax eax in 32 bit)
; 665  :           sub		rax, 8					// back up to last 8 pixels // P.F. 16.04.28 should be rax here not eax (hack! define rax eax in 32 bit)
; 666  :           jmp		vLoopMMX
; 667  : 
; 668  :           // Do vertical END This one already ported to intrinsics (SSE2 mod16) + rest C
; 669  : 
; 670  : //-----------------------------------------------------
; 671  :          // We've taken care of the vertical scaling, now do horizontal
; 672  :         DoHorizontal:
; 673  :         pxor    mm7, mm7
; 674  :           movq	mm6, FPround2		// useful rounding constant, dwords
; 675  :           mov		rsi, pControl		// @ horiz control bytes			
; 676  :           mov		ecx, row_size
; 677  :           shr		ecx, 2				// 4 bytes a time, 4 pixels
; 678  :           mov     rdx, vWorkYW		// our luma data
; 679  :           mov		rdi, dstp			// the destination line
; 680  :           test    SSEMMXenabledW, 1		// is SSE2 supported?
; 681  :           jz		hLoopMMX				// n
; 682  : 
; 683  :     // With SSE support we will make 8 pixels (from 8 pairs) at a time
; 684  :           shr		ecx, 1				// 8 bytes a time instead of 4
; 685  :           jz		LessThan8
; 686  :           align 16
; 687  :           hLoopMMXSSE:
; 688  :         // handle first 2 pixels			
; 689  :         mov		eax, [rsi + 16]		// EAX! get data offset in pixels, 1st pixel pair 
; 690  :           mov		ebx, [rsi + 20]		// EBX! get data offset in pixels, 2nd pixel pair 
; 691  :           movd	mm0, [rdx + rax]		// copy luma pair 0000xxYY
; 692  :           punpcklwd mm0, [rdx + rbx]    // 2nd luma pair, now xxxxYYYY
; 693  :           punpcklbw mm0, mm7		    // make words out of bytes, 0Y0Y0Y0Y
; 694  :           mov		eax, [rsi + 16 + 24]	// EAX! get data offset in pixels, 3rd pixel pair 
; 695  :           mov		ebx, [rsi + 20 + 24]	// EBX! get data offset in pixels, 4th pixel pair 
; 696  :           pmaddwd mm0, [rsi]			// mult and sum lumas by ctl weights
; 697  :           paddusw	mm0, mm6			// round
; 698  :           psrlw	mm0, 8				// right just 4 luma pixel value 0Y0Y0Y0Y
; 699  : 
; 700  :           // handle 3rd and 4th pixel pairs			
; 701  :           movd	mm1, [rdx + rax]		// copy luma pair 0000xxYY
; 702  :           punpcklwd mm1, [rdx + rbx]    // 2nd luma pair, now xxxxYYYY
; 703  :           punpcklbw mm1, mm7		    // make words out of bytes, 0Y0Y0Y0Y
; 704  :           mov		eax, [rsi + 16 + 48]	// EAX! get data offset in pixels, 5th pixel pair 
; 705  :           mov		ebx, [rsi + 20 + 48]	// EBX! get data offset in pixels, 6th pixel pair 
; 706  :           pmaddwd mm1, [rsi + 24]		// mult and sum lumas by ctl weights
; 707  :           paddusw	mm1, mm6			// round
; 708  :           psrlw	mm1, 8				// right just 4 luma pixel value 0Y0Y0Y0Y
; 709  : 
; 710  :           // handle 5th and 6th pixel pairs			
; 711  :           movd	mm2, [rdx + rax]		// copy luma pair 0000xxYY
; 712  :           punpcklwd mm2, [rdx + rbx]    // 2nd luma pair, now xxxxYYYY
; 713  :           punpcklbw mm2, mm7		    // make words out of bytes, 0Y0Y0Y0Y
; 714  :           mov		eax, [rsi + 16 + 72]	// EAX! get data offset in pixels, 7th pixel pair 
; 715  :           mov		ebx, [rsi + 20 + 72]	// EBX! get data offset in pixels, 8th pixel pair 
; 716  :           pmaddwd mm2, [rsi + 48]			// mult and sum lumas by ctl weights
; 717  :           paddusw	mm2, mm6			// round
; 718  :           psrlw	mm2, 8				// right just 4 luma pixel value 0Y0Y0Y0Y
; 719  : 
; 720  :           // handle 7th and 8th pixel pairs			
; 721  :           movd	mm3, [rdx + rax]		// copy luma pair
; 722  :           punpcklwd mm3, [rdx + rbx]    // 2nd luma pair
; 723  :           punpcklbw mm3, mm7		    // make words out of bytes
; 724  :           pmaddwd mm3, [rsi + 72]		// mult and sum lumas by ctl weights
; 725  :  // _mm_adds_epu16
; 726  :           paddusw	mm3, mm6			// round
; 727  :           psrlw	mm3, 8				// right just 4 luma pixel value 0Y0Y0Y0Y
; 728  : 
; 729  :           // combine, store, and loop
; 730  :           packuswb mm0, mm1			// pack into qword, 0Y0Y0Y0Y
; 731  :           packuswb mm2, mm3			// pack into qword, 0Y0Y0Y0Y
; 732  :           packuswb mm0, mm2			// and again into  YYYYYYYY				
; 733  :           movntq	qword ptr[rdi], mm0	// done with 4 pixels
; 734  : 
; 735  :           lea    rsi, [rsi + 96]		// bump to next control bytest
; 736  :           lea    rdi, [rdi + 8]			// bump to next output pixel addr
; 737  :           dec	   ecx
; 738  :           jg	   hLoopMMXSSE				// loop for more
; 739  :           sfence
; 740  : 
; 741  :           LessThan8 :
; 742  :         mov		ecx, row_size
; 743  :           and		ecx, 7				// we have done all but maybe this
; 744  :           shr		ecx, 2				// now do only 4 bytes at a time
; 745  :           jz		LessThan4
; 746  : 
; 747  :           align 16
; 748  :           hLoopMMX:
; 749  :         // handle first 2 pixels			
; 750  :         mov		eax, [rsi + 16]		// EAX! get data offset in pixels, 1st pixel pair 
; 751  :           mov		ebx, [rsi + 20]		// EBX! get data offset in pixels, 2nd pixel pair 
; 752  :           movd	mm0, [rdx + rax]		// copy luma pair 0000xxYY
; 753  :           punpcklwd mm0, [rdx + rbx]    // 2nd luma pair, now xxxxYYYY
; 754  :           punpcklbw mm0, mm7		    // make words out of bytes, 0Y0Y0Y0Y
; 755  :           mov		eax, [rsi + 16 + 24]	// get data offset in pixels, 3rd pixel pair
; 756  :           mov		ebx, [rsi + 20 + 24]	// get data offset in pixels, 4th pixel pair
; 757  :           pmaddwd mm0, [rsi]			// mult and sum lumas by ctl weights
; 758  :           paddusw	mm0, mm6			// round
; 759  :           psrlw	mm0, 8				// right just 4 luma pixel value 0Y0Y0Y0Y
; 760  : 
; 761  :           // handle 3rd and 4th pixel pairs			
; 762  :           movd	mm1, [rdx + rax]		// copy luma pair
; 763  :           punpcklwd mm1, [rdx + rbx]    // 2nd luma pair
; 764  :           punpcklbw mm1, mm7		    // make words out of bytes
; 765  :           pmaddwd mm1, [rsi + 24]			// mult and sum lumas by ctl weights
; 766  :           paddusw	mm1, mm6			// round
; 767  :           psrlw	mm1, 8				// right just 4 luma pixel value 0Y0Y0Y0Y
; 768  : 
; 769  :           // combine, store, and loop
; 770  :           packuswb mm0, mm1			// pack all into qword, 0Y0Y0Y0Y
; 771  :           packuswb mm0, mm7			// and again into  0000YYYY				
; 772  :           movd	dword ptr[rdi], mm0	// done with 4 pixels
; 773  :           lea    rsi, [rsi + 48]		// bump to next control bytest
; 774  :           lea    rdi, [rdi + 4]			// bump to next output pixel addr
; 775  :           loop   hLoopMMX				// loop for more
; 776  : 
; 777  :     // test to see if we have a mod 4 size row, if not then more spare change
; 778  :           LessThan4 :
; 779  :         mov		ecx, row_size
; 780  :           and		ecx, 3				// remainder size mod 4
; 781  :           cmp		ecx, 2
; 782  :           jl		LastOne				// none, done
; 783  : 
; 784  :           // handle 2 more pixels			
; 785  :           mov		eax, [rsi + 16]		// EAX! get data offset in pixels, 1st pixel pair 
; 786  :           mov		ebx, [rsi + 20]		// EBX! get data offset in pixels, 2nd pixel pair 
; 787  :           movd	mm0, [rdx + rax]		// copy luma pair 0000xxYY
; 788  :           punpcklwd mm0, [rdx + rbx]    // 2nd luma pair, now xxxxYYYY
; 789  :           punpcklbw mm0, mm7		    // make words out of bytes, 0Y0Y0Y0Y
; 790  : 
; 791  :           pmaddwd mm0, [rsi]			// mult and sum lumas by ctl weights
; 792  :           paddusw	mm0, mm6			// round
; 793  :           psrlw	mm0, 8				// right just 2 luma pixel value 000Y,000Y
; 794  :           packuswb mm0, mm7			// pack all into qword, 00000Y0Y
; 795  :           packuswb mm0, mm7			// and again into  000000YY		
; 796  :           movd	dword ptr[rdi], mm0	// store, we are guarrenteed room in buffer (8 byte mult)
; 797  :           sub		ecx, 2
; 798  :           lea		rsi, [rsi + 24]		// bump to next control bytest
; 799  :           lea		rdi, [rdi + 2]			// bump to next output pixel addr
; 800  : 
; 801  :           // maybe one last pixel
; 802  :           LastOne:
; 803  :         cmp		ecx, 0				// still more?
; 804  :           jz		AllDone				// n, done
; 805  : 
; 806  :           mov		eax, [rsi + 16]		// EAX! get data offset in pixels, 1st pixel pair 
; 807  :           movd	mm0, [rdx + rax]		// copy luma pair 0000xxYY
; 808  :           punpcklbw mm0, mm7		    // make words out of bytes, xxxx0Y0Y
; 809  : 
; 810  :           pmaddwd mm0, [rsi]			// mult and sum lumas by ctl weights
; 811  :           paddusw	mm0, mm6			// round
; 812  :           psrlw	mm0, 8				// right just 2 luma pixel value xxxx000Y
; 813  :           movd	eax, mm0
; 814  :           mov		byte ptr[rdi], al	// store last one
; 815  : 
; 816  :           AllDone :
; 817  :         //pop		ecx Intel2017:should be commented out
; 818  :         emms
; 819  :       }
; 820  :     }                               // done with one line
; 821  : #endif // MSVC x64 asm ignore
; 822  : 
; 823  :     dstp += dst_pitch;

	add	edi, DWORD PTR _dst_pitch$[esp+40]
	add	edx, 4
	mov	ebx, DWORD PTR _vWorkYW$1$[esp+44]
	mov	esi, DWORD PTR _vWeightsW$1$[esp+44]
	mov	DWORD PTR _dstp$1$[esp+40], edi
	mov	DWORD PTR _y$1$[esp+44], ecx
	mov	DWORD PTR _vOffsetsW$1$[esp+44], edx
	cmp	ecx, DWORD PTR _height$[esp+40]
	jl	$LL4@SimpleResi
	pop	edi
	pop	ebp
$LN32@SimpleResi:
	pop	esi
	pop	ebx

; 824  :   }
; 825  : 
; 826  : }

	add	esp, 28					; 0000001cH
	ret	32					; 00000020H
?SimpleResizeDo_uint8@SimpleResize@@QAEXPAEHHHPBEHHH@Z ENDP ; SimpleResize::SimpleResizeDo_uint8
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File c:\github\mvtools\sources\simpleresize.cpp
;	COMDAT ?SimpleResizeDo_uint16@SimpleResize@@QAEXPAFHHHPBFHH@Z
_TEXT	SEGMENT
_vWorkYW$1$ = -68					; size = 4
_x$1$ = -64						; size = 4
_dstp$1$ = -60						; size = 4
_srcp2$1$ = -56						; size = 4
_y$1$ = -52						; size = 4
_vOffsetsW$1$ = -48					; size = 4
tv1216 = -44						; size = 4
tv1207 = -40						; size = 4
tv1198 = -36						; size = 4
tv1205 = -32						; size = 4
tv1199 = -28						; size = 4
_srcp1$1$ = -24						; size = 4
_invCurrentWeight$1$ = -20				; size = 4
_CurrentWeight$1$ = -16					; size = 4
_pControl$1$ = -12					; size = 4
tv1212 = -8						; size = 4
_vWeightsW$1$ = -4					; size = 4
_dstp$ = 8						; size = 4
_row_size$ = 12						; size = 4
_height$ = 16						; size = 4
_dst_pitch$ = 20					; size = 4
_srcp$ = 24						; size = 4
_src_row_size$ = 28					; size = 4
_src_pitch$ = 32					; size = 4
?SimpleResizeDo_uint16@SimpleResize@@QAEXPAFHHHPBFHH@Z PROC ; SimpleResize::SimpleResizeDo_uint16, COMDAT
; _this$ = ecx

; 832  : {

	push	ebp
	mov	ebp, esp
	and	esp, -8					; fffffff8H
	sub	esp, 68					; 00000044H

; 833  :   if (SSE2enabled) {

	cmp	BYTE PTR [ecx+36], 0
	push	ebx
	push	esi
	push	edi
	je	SHORT $LN11@SimpleResi

; 834  :     SimpleResizeDo_New<short>((uint8_t *)dstp, row_size, height, dst_pitch, (uint8_t *)srcp, src_row_size, src_pitch);

	push	DWORD PTR _src_pitch$[ebp]
	push	DWORD PTR _src_row_size$[ebp]
	push	DWORD PTR _srcp$[ebp]
	push	DWORD PTR _dst_pitch$[ebp]
	push	DWORD PTR _height$[ebp]
	push	DWORD PTR _row_size$[ebp]
	push	DWORD PTR _dstp$[ebp]
	call	??$SimpleResizeDo_New@F@SimpleResize@@QAEXPAEHHHPBEHH@Z ; SimpleResize::SimpleResizeDo_New<short>

; 1061 :   }
; 1062 : 
; 1063 : }

	pop	edi
	pop	esi
	pop	ebx
	mov	esp, ebp
	pop	ebp
	ret	28					; 0000001cH
$LN11@SimpleResi:

; 835  :     return;
; 836  :   }
; 837  : 
; 838  :   int vWeight1[4];
; 839  :   int vWeight2[4];
; 840  :   const __int64 FPround2[2] = { 0x0000008000000080,0x0000008000000080 };// round dwords
; 841  : 
; 842  :   const unsigned int* pControl = &hControl[0];

	mov	eax, DWORD PTR [ecx+16]

; 843  : 
; 844  :   const  short* srcp1;
; 845  :   const  short* srcp2;
; 846  :   short* vWorkYW = vWorkY2;
; 847  : 
; 848  :   unsigned int* vOffsetsW = vOffsets;
; 849  : 
; 850  :   unsigned int* vWeightsW = vWeights;
; 851  : 
; 852  :   for (int y = 0; y < height; y++)

	xor	edx, edx
	mov	esi, DWORD PTR [ecx+32]
	mov	ebx, DWORD PTR [ecx+20]
	mov	ecx, DWORD PTR [ecx+24]
	mov	DWORD PTR _pControl$1$[esp+80], eax
	mov	eax, DWORD PTR _height$[ebp]
	mov	DWORD PTR _vWorkYW$1$[esp+80], esi
	mov	DWORD PTR _vOffsetsW$1$[esp+80], ebx
	mov	DWORD PTR _y$1$[esp+80], edx
	test	eax, eax
	jle	$LN3@SimpleResi
	lea	edi, DWORD PTR [eax-1]
	mov	eax, DWORD PTR _dst_pitch$[ebp]
	add	eax, eax
	mov	DWORD PTR tv1216[esp+80], edi
	mov	DWORD PTR tv1212[esp+80], eax
	sub	ecx, ebx
	mov	eax, DWORD PTR _dstp$[ebp]
	mov	DWORD PTR _vWeightsW$1$[esp+80], ecx
	mov	DWORD PTR _dstp$1$[esp+80], eax
	npad	5
$LL4@SimpleResi:

; 853  :   {
; 854  : 
; 855  :     int CurrentWeight = vWeightsW[y];

	mov	ecx, DWORD PTR [ecx+ebx]

; 856  :     int invCurrentWeight = 256 - CurrentWeight;

	mov	eax, 256				; 00000100H
	sub	eax, ecx
	mov	DWORD PTR _CurrentWeight$1$[esp+80], ecx
	mov	DWORD PTR _invCurrentWeight$1$[esp+80], eax
	movd	xmm0, ecx

; 857  : 
; 858  :     // fill 4x(16x2) bit for inline asm 
; 859  :     // for intrinsic it is not needed anymore
; 860  :     vWeight1[0] = vWeight1[1] = vWeight1[2] = vWeight1[3] =
; 861  :       (invCurrentWeight << 16) | invCurrentWeight;
; 862  : 
; 863  :     vWeight2[0] = vWeight2[1] = vWeight2[2] = vWeight2[3] =
; 864  :       (CurrentWeight << 16) | CurrentWeight;
; 865  : 
; 866  :     srcp1 = srcp + vOffsetsW[y] * src_pitch;

	mov	ecx, DWORD PTR _src_pitch$[ebp]
	pshufd	xmm4, xmm0, 0
	movd	xmm0, eax
	mov	eax, DWORD PTR [ebx]
	mov	ebx, DWORD PTR _srcp$[ebp]
	imul	eax, ecx
	pshufd	xmm5, xmm0, 0
	lea	edi, DWORD PTR [ebx+eax*2]
	mov	DWORD PTR _srcp1$1$[esp+80], edi

; 867  : 
; 868  :     // scrp2 is the next line (check for the most bottom line)
; 869  :     srcp2 = (y < height - 1) ? srcp1 + src_pitch : srcp1;

	cmp	edx, DWORD PTR tv1216[esp+80]
	jge	SHORT $LN16@SimpleResi
	lea	ecx, DWORD PTR [edi+ecx*2]
	mov	DWORD PTR _srcp2$1$[esp+80], ecx
	jmp	SHORT $LN17@SimpleResi
$LN16@SimpleResi:
	mov	ecx, edi
	mov	DWORD PTR _srcp2$1$[esp+80], edi
$LN17@SimpleResi:

; 870  : 
; 871  :     if (true) // make it true for C version
; 872  :     {
; 873  :       // recovered (and commented) C version as sort of doc
; 874  :       for (int x = 0; x < src_row_size; x++) {

	mov	eax, DWORD PTR _src_row_size$[ebp]
	xor	edx, edx
	mov	DWORD PTR _x$1$[esp+80], edx
	test	eax, eax
	jle	$LN6@SimpleResi
	cmp	eax, 8
	jb	$LN25@SimpleResi

; 875  :         vWorkYW[x] = (srcp1[x] * invCurrentWeight + srcp2[x] * CurrentWeight + 128) >> 8;

	cmp	DWORD PTR ___isa_available, 2
	jl	$LN25@SimpleResi
	lea	ebx, DWORD PTR [eax-1]
	mov	DWORD PTR _x$1$[esp+80], edx
	dec	eax
	lea	ebx, DWORD PTR [esi+ebx*2]
	lea	eax, DWORD PTR [ecx+eax*2]
	cmp	esi, eax
	ja	SHORT $LN26@SimpleResi
	cmp	ebx, ecx
	jae	$LN39@SimpleResi
$LN26@SimpleResi:
	mov	eax, DWORD PTR _src_row_size$[ebp]
	dec	eax
	lea	eax, DWORD PTR [edi+eax*2]
	cmp	esi, eax
	ja	SHORT $LN27@SimpleResi
	cmp	ebx, edi
	jae	$LN39@SimpleResi
$LN27@SimpleResi:
	mov	edx, DWORD PTR _src_row_size$[ebp]
	mov	eax, edx
	and	eax, -2147483641			; 80000007H
	jns	SHORT $LN40@SimpleResi
	dec	eax
	or	eax, -8					; fffffff8H
	inc	eax
$LN40@SimpleResi:
	movaps	xmm2, XMMWORD PTR __xmm@00000080000000800000008000000080
	sub	edx, eax
	mov	DWORD PTR tv1199[esp+80], edx
	mov	eax, 8

; 870  : 
; 871  :     if (true) // make it true for C version
; 872  :     {
; 873  :       // recovered (and commented) C version as sort of doc
; 874  :       for (int x = 0; x < src_row_size; x++) {

	mov	edx, edi
	mov	ebx, esi
	sub	edx, ecx
	mov	DWORD PTR tv1207[esp+80], edx
	mov	edx, esi
	sub	edx, ecx
	movd	xmm3, eax
	mov	DWORD PTR tv1198[esp+80], edx
	lea	eax, DWORD PTR [ecx+8]
	mov	edx, edi
	mov	edi, DWORD PTR tv1198[esp+80]
	sub	edx, esi
	mov	esi, DWORD PTR tv1207[esp+80]
	mov	DWORD PTR tv1205[esp+80], edx
	mov	edx, DWORD PTR _x$1$[esp+80]
	mov	ecx, DWORD PTR tv1205[esp+80]
$LL7@SimpleResi:
	movq	xmm0, QWORD PTR [ecx+ebx]
	lea	ebx, DWORD PTR [ebx+16]

; 875  :         vWorkYW[x] = (srcp1[x] * invCurrentWeight + srcp2[x] * CurrentWeight + 128) >> 8;

	pmovsxwd xmm1, xmm0
	movq	xmm0, QWORD PTR [eax-8]
	lea	eax, DWORD PTR [eax+16]
	pmovsxwd xmm0, xmm0
	pmulld	xmm0, xmm4
	pmulld	xmm1, xmm5
	paddd	xmm1, xmm0
	add	edx, 8
	paddd	xmm1, xmm2
	psrad	xmm1, xmm3
	pshuflw	xmm0, xmm1, 216				; 000000d8H
	pshufhw	xmm0, xmm0, 216				; 000000d8H
	pshufd	xmm0, xmm0, 216				; 000000d8H
	movq	QWORD PTR [ebx-16], xmm0
	movq	xmm0, QWORD PTR [esi+eax-16]
	pmovsxwd xmm1, xmm0
	movq	xmm0, QWORD PTR [eax-16]
	pmovsxwd xmm0, xmm0
	pmulld	xmm0, xmm4
	pmulld	xmm1, xmm5
	paddd	xmm1, xmm0
	paddd	xmm1, xmm2
	psrad	xmm1, xmm3
	pshuflw	xmm0, xmm1, 216				; 000000d8H
	pshufhw	xmm0, xmm0, 216				; 000000d8H
	pshufd	xmm0, xmm0, 216				; 000000d8H
	movq	QWORD PTR [eax+edi-16], xmm0
	cmp	edx, DWORD PTR tv1199[esp+80]
	jl	$LL7@SimpleResi
	mov	edi, DWORD PTR _srcp1$1$[esp+80]
	mov	ecx, DWORD PTR _srcp2$1$[esp+80]
	mov	esi, DWORD PTR _vWorkYW$1$[esp+80]
	mov	DWORD PTR _x$1$[esp+80], edx
$LN39@SimpleResi:
	mov	eax, DWORD PTR _src_row_size$[ebp]
$LN25@SimpleResi:

; 870  : 
; 871  :     if (true) // make it true for C version
; 872  :     {
; 873  :       // recovered (and commented) C version as sort of doc
; 874  :       for (int x = 0; x < src_row_size; x++) {

	cmp	edx, eax
	jge	SHORT $LN6@SimpleResi
	mov	ebx, esi
	lea	edx, DWORD PTR [ecx+edx*2]
	mov	esi, eax
	sub	edi, ecx
	sub	ebx, ecx
	sub	esi, DWORD PTR _x$1$[esp+80]
	npad	6
$LL24@SimpleResi:

; 875  :         vWorkYW[x] = (srcp1[x] * invCurrentWeight + srcp2[x] * CurrentWeight + 128) >> 8;

	movsx	eax, WORD PTR [edx]
	lea	edx, DWORD PTR [edx+2]
	imul	eax, DWORD PTR _CurrentWeight$1$[esp+80]
	movsx	ecx, WORD PTR [edx+edi-2]
	imul	ecx, DWORD PTR _invCurrentWeight$1$[esp+80]
	sub	eax, -128				; ffffff80H
	add	eax, ecx
	sar	eax, 8
	mov	WORD PTR [edx+ebx-2], ax
	sub	esi, 1
	jne	SHORT $LL24@SimpleResi
	mov	esi, DWORD PTR _vWorkYW$1$[esp+80]
$LN6@SimpleResi:

; 876  :       }
; 877  :       // We've taken care of the vertical scaling, now do horizontal
; 878  :       for (int x = 0; x < row_size; x++) {

	xor	ebx, ebx
	cmp	DWORD PTR _row_size$[ebp], ebx
	jle	SHORT $LN37@SimpleResi
	mov	eax, DWORD PTR _pControl$1$[esp+80]
	add	eax, -8					; fffffff8H
	npad	7
$LL10@SimpleResi:

; 879  :         unsigned int pc;
; 880  :         unsigned int offs;
; 881  :         if ((x & 1) == 0) { // even

	test	bl, 1
	jne	SHORT $LN13@SimpleResi

; 882  :           pc = pControl[3 * x];

	mov	edx, DWORD PTR [eax+8]

; 883  :           offs = pControl[3 * x + 4];

	mov	edi, DWORD PTR [eax+24]

; 884  :         }
; 885  :         else { // odd

	jmp	SHORT $LN14@SimpleResi
$LN13@SimpleResi:

; 886  :           pc = pControl[3 * x - 2]; // [3*xeven+1]

	mov	edx, DWORD PTR [eax]

; 887  :           offs = pControl[3 * x + 2]; // [3*xeven+5]

	mov	edi, DWORD PTR [eax+16]
$LN14@SimpleResi:

; 888  :         }
; 889  :         unsigned int wY1 = pc & 0x0000ffff; //low
; 890  :         unsigned int wY2 = pc >> 16; //high
; 891  :         dstp[x] = (vWorkYW[offs] * wY1 + vWorkYW[offs + 1] * wY2 + 128) >> 8;

	movsx	esi, WORD PTR [esi+edi*2+2]
	mov	ecx, edx
	shr	ecx, 16					; 00000010H
	add	eax, 12					; 0000000cH
	imul	esi, ecx
	mov	ecx, DWORD PTR _vWorkYW$1$[esp+80]
	movzx	edx, dx
	movsx	ecx, WORD PTR [ecx+edi*2]
	sub	esi, -128				; ffffff80H
	imul	ecx, edx
	mov	edx, DWORD PTR _dstp$1$[esp+80]
	add	ecx, esi
	mov	esi, DWORD PTR _vWorkYW$1$[esp+80]
	shr	ecx, 8
	mov	WORD PTR [edx+ebx*2], cx
	inc	ebx
	cmp	ebx, DWORD PTR _row_size$[ebp]
	jl	SHORT $LL10@SimpleResi
	jmp	SHORT $LN9@SimpleResi
$LN37@SimpleResi:
	mov	edx, DWORD PTR _dstp$1$[esp+80]
$LN9@SimpleResi:

; 892  :       }
; 893  :     }
; 894  : #if 0
; 895  :     // inline asm ignored for MSVC X64 build: !(defined(_M_X64) && defined(_MSC_VER))
; 896  :     else {
; 897  : 
; 898  :       _asm
; 899  :       { // MMX resizer code adopted to sized short int
; 900  :         //push	ecx Intel2017:should be commented out
; 901  :         mov		ecx, src_row_size // size in words
; 902  :         shr		ecx, 2					// 8 bytes = 4 words a time
; 903  :         mov		rsi, srcp1				// top of 2 src lines to get
; 904  :         mov		rdx, srcp2				// next "
; 905  :         mov		rdi, vWorkYW			// luma work destination line
; 906  :         xor		rax, rax                // P.F. 16.04.28 should be rax here not eax (hack! define rax eax in 32 bit)
; 907  :         xor       rbx, rbx                // P.F. 16.04.28 leater only ebx used
; 908  : 
; 909  :         movq	mm5, vWeight1
; 910  :         movq	mm6, vWeight2
; 911  :         movq	mm0, FPround2			// useful rounding constant
; 912  :         pxor	mm7, mm7
; 913  :         align	16
; 914  :         vLoopMMX:
; 915  :         movq	mm1, qword ptr[rsi + rax * 2] // top of 2 lines to interpolate (4 vectors)
; 916  :           movq	mm3, qword ptr[rdx + rax * 2] // 2nd of 2 lines (4 vectors)
; 917  :           movq	mm2, mm1				// copy top bytes
; 918  :           movq	mm4, mm3				// copy 2nd bytes
; 919  : 
; 920  :           //__m128i _mm_mullo_epi16 (__m128i a, __m128i b);
; 921  :           pmullw	mm1, mm5				// mult by weighting factor
; 922  :           //__m128i _mm_mulhi_epi16 (__m128i a, __m128i b);
; 923  :           pmulhw	mm2, mm5				// mult by weighting factor, high
; 924  :           pmullw	mm3, mm6				// mult by weighting factor
; 925  :           pmulhw	mm4, mm6				// mult by weighting factor, high
; 926  : 
; 927  :           movq    mm7, mm1 // copy
; 928  :           // _mm_unpacklo_epi16
; 929  :           punpcklwd mm1, mm2 // double from low and high
; 930  :           // _mm_unpackhi_epi16
; 931  :           punpckhwd mm7, mm2 // double from low and high
; 932  : 
; 933  :           movq    mm2, mm3 // copy
; 934  :           punpcklwd mm3, mm4 // double from low and high
; 935  :           punpckhwd mm2, mm4 // double from low and high
; 936  :            // __m128i _mm_add_epi32 (__m128i a, __m128i b);
; 937  :           paddd	mm1, mm3				// combine lumas
; 938  :           paddd	mm2, mm7				// combine lumas
; 939  : 
; 940  :           paddd	mm1, mm0				// round
; 941  :           paddd	mm2, mm0				// round
; 942  : 
; 943  :           // _mm_sra_epi32
; 944  :           psrad	mm1, 8					// right just
; 945  :           psrad	mm2, 8					// right just
; 946  : 
; 947  :           //_mm_packs_epi32
; 948  :           packssdw mm1, mm2				// pack into 4 words
; 949  : 
; 950  :           movq	qword ptr[rdi + rax * 2], mm1	// save 4 words in our work area 
; 951  : 
; 952  :           lea     rax, [rax + 4]
; 953  :           loop	vLoopMMX // decrement ecx
; 954  : 
; 955  :                    // Add a little code here to check if we have more pixels to do and, if so, make one
; 956  :                    // more pass thru vLoopMMX. We were processing in multiples of 8 pixels and alway have
; 957  :                    // an even number so there will never be more than 7 left.
; 958  :                    //	MoreSpareChange:
; 959  :           cmp		eax, src_row_size		// EAX! did we get them all
; 960  :           jnl		DoHorizontal			// yes, else have 2 left
; 961  :           mov		ecx, 1					// jigger loop ct
; 962  :           mov		eax, src_row_size       // EAX!
; 963  :           sub		eax, 4					// back up to last 8 pixels
; 964  :           jmp		vLoopMMX
; 965  : 
; 966  :           // We've taken care of the vertical scaling, now do horizontal
; 967  :           // x pixels at a time
; 968  :           DoHorizontal :
; 969  :         pxor    mm7, mm7
; 970  :           movq	mm6, FPround2		// useful rounding constant, dwords
; 971  :           mov		rsi, pControl		// @ horiz control bytes
; 972  :           mov		ecx, row_size // size in words
; 973  :           shr		ecx, 2				// 8 bytes a time, 4 words
; 974  :           mov     rdx, vWorkYW		// our luma data
; 975  :           mov		rdi, dstp			// the destination line
; 976  :           align 16
; 977  :           hLoopMMX:
; 978  :         // handle first 2 pixels
; 979  :         mov		eax, [rsi + 16]		// EAX! get data offset in pixels, 1st pixel pair. Control[4]=offs
; 980  :           mov		ebx, [rsi + 20]		// EBX! get data offset in pixels, 2nd pixel pair. Control[5]=offsodd
; 981  :           // (uint32_t)pair1     = (uint32_t *)((short *)(vWorkYW)[offs])      // vWorkYW[offs] and vWorkYW[offs+1]
; 982  :           // (uint32_t)pair2odds = (uint32_t *)((short *)(vWorkYW)[offsodds])  // vWorkYW[offsodds] and vWorkYW[offsodds+1]
; 983  : 
; 984  :           // using only 64 bit MMX registers
; 985  :             // __m128i _mm_cvtsi32_si128 (uint32_t*(vWorkYW)[offs]);
; 986  :             // __m128i _mm_cvtsi64_si128 (uint32_t*(vWorkYW)[offs]);
; 987  :           movd	mm0, [rdx + rax * 2]		// copy luma pair 0000W1W0  work[offs]
; 988  :             // _mm_unpacklo_epi32 (mm0, uint32_t*(&ushort*(vWorkYW)[offsodd])
; 989  :           punpckldq mm0, [rdx + rbx * 2]    // 2nd luma pair, now V1V0W1W0
; 990  :             // _mm_madd_epi16(.. PControl[0-1])
; 991  :           pmaddwd mm0, [rsi]			// mult and sum lumas by ctl weights. v1v0 Control[1] and w1w0 Control[0]
; 992  :             // _mm_add_epi32
; 993  :           paddd	mm0, mm6			// round
; 994  :             // _mm_srai_epi32
; 995  :           psrad	mm0, 8				// right just 2 luma pixel
; 996  : 
; 997  :                     // handle 3rd and 4th pixel pairs
; 998  :           mov		eax, [rsi + 16 + 24]	// EAX! get data offset in pixels, 3rd pixel pair. Control[4+6}
; 999  :           mov		ebx, [rsi + 20 + 24]	// EBX! get data offset in pixels, 4th pixel pair. Control[5+6}
; 1000 :           movd	mm1, [rdx + rax * 2]		// copy luma pair
; 1001 :           punpckldq mm1, [rdx + rbx * 2]    // 2nd luma pair
; 1002 :           pmaddwd mm1, [rsi + 24]		// mult and sum lumas by ctl weights. Control[6] and Control[7]
; 1003 :           paddd	mm1, mm6			// round
; 1004 :           psrad	mm1, 8				// right just 2 luma pixel
; 1005 : 
; 1006 :                     // combine, store, and loop
; 1007 :             // _mm_packs_epi32
; 1008 :           packssdw mm0, mm1			// pack all 4 into qword, 0Y0Y0Y0Y
; 1009 :             // store 4 word, 8 bytes
; 1010 :             // _mm_move_epi64
; 1011 :           movq	qword ptr[rdi], mm0	// done with 4 pixels
; 1012 : 
; 1013 :           lea    rsi, [rsi + 48]		// bump to next control bytest. Control[12]
; 1014 :           lea    rdi, [rdi + 8]			// bump to next output pixel addr
; 1015 :           loop   hLoopMMX				// loop for more
; 1016 : 
; 1017 :                       // test to see if we have a mod 4 size row, if not then more spare change
; 1018 :                       //	LessThan4:
; 1019 :           mov		ecx, row_size
; 1020 :           and		ecx, 3				// remainder size mod 4
; 1021 :           cmp		ecx, 2
; 1022 :           jl		LastOne				// none, done
; 1023 : 
; 1024 :                     // handle 2 more pixels
; 1025 :           mov		eax, [rsi + 16]		// EAX! get data offset in pixels, 1st pixel pair
; 1026 :           mov		ebx, [rsi + 20]		// EBX! get data offset in pixels, 2nd pixel pair
; 1027 :           movd	mm0, [rdx + rax * 2]		// copy luma pair 0000xxYY
; 1028 :           punpckldq mm0, [rdx + rbx * 2]    // 2nd luma pair, now xxxxYYYY
; 1029 : 
; 1030 :           pmaddwd mm0, [rsi]			// mult and sum lumas by ctl weights
; 1031 :           paddd	mm0, mm6			// round
; 1032 :           psrad	mm0, 8				// right just 2 luma pixel value 000Y,000Y
; 1033 :           packssdw mm0, mm7			// and again into  00000Y0Y
; 1034 :           movd	dword ptr[rdi], mm0	// store, we are guarrenteed room in buffer (8 byte mult)
; 1035 :           sub		ecx, 2
; 1036 :           lea		rsi, [rsi + 24]		// bump to next control bytest
; 1037 :           lea		rdi, [rdi + 4]			// bump to next output pixel addr
; 1038 : 
; 1039 :                         // maybe one last pixel
; 1040 :           LastOne:
; 1041 :         cmp		ecx, 0				// still more?
; 1042 :           jz		AllDone				// n, done
; 1043 : 
; 1044 :           mov		eax, [rsi + 16]		// EAX! get data offset in pixels, 1st pixel pair
; 1045 :           movd	mm0, [rdx + rax * 2]		// copy luma pair 0000xxYY
; 1046 :           punpckldq mm0, mm7		    // make dwords out of words, xxxx0Y0Y
; 1047 : 
; 1048 :           pmaddwd mm0, [rsi]			// mult and sum lumas by ctl weights
; 1049 :           paddd	mm0, mm6			// round
; 1050 :           psrad	mm0, 8				// right just 1 luma pixel value xxxx000Y
; 1051 :           movd	eax, mm0
; 1052 :           mov		word ptr[rdi], ax	// store last one
; 1053 : 
; 1054 :           AllDone :
; 1055 :         //pop		ecx Intel2017:should be commented out
; 1056 :         emms
; 1057 :       }
; 1058 :     }
; 1059 : #endif // asm ignore
; 1060 :     dstp += dst_pitch;

	add	edx, DWORD PTR tv1212[esp+80]
	mov	ebx, DWORD PTR _vOffsetsW$1$[esp+80]
	mov	esi, DWORD PTR _vWorkYW$1$[esp+80]
	add	ebx, 4
	mov	ecx, DWORD PTR _vWeightsW$1$[esp+80]
	mov	DWORD PTR _dstp$1$[esp+80], edx
	mov	edx, DWORD PTR _y$1$[esp+80]
	inc	edx
	mov	DWORD PTR _vOffsetsW$1$[esp+80], ebx
	mov	DWORD PTR _y$1$[esp+80], edx
	cmp	edx, DWORD PTR _height$[ebp]
	jl	$LL4@SimpleResi
$LN3@SimpleResi:

; 1061 :   }
; 1062 : 
; 1063 : }

	pop	edi
	pop	esi
	pop	ebx
	mov	esp, ebp
	pop	ebp
	ret	28					; 0000001cH
?SimpleResizeDo_uint16@SimpleResize@@QAEXPAFHHHPBFHH@Z ENDP ; SimpleResize::SimpleResizeDo_uint16
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File c:\github\mvtools\sources\simpleresize.cpp
;	COMDAT ?InitTables@SimpleResize@@AAEXXZ
_TEXT	SEGMENT
tv683 = -4						; size = 4
?InitTables@SimpleResize@@AAEXXZ PROC			; SimpleResize::InitTables, COMDAT
; _this$ = ecx

; 1080 : {

	push	ecx
	push	ebx
	push	ebp

; 1081 :   int i;
; 1082 :   int j;
; 1083 :   int k;
; 1084 :   int wY1;
; 1085 :   int wY2;
; 1086 : 
; 1087 :   // First set up horizontal table, use for both luma & chroma since 
; 1088 :   // it seems to have the same equation.
; 1089 :   // We will geneerate these values in pairs, mostly because that's the way
; 1090 :   // I wrote it for YUY2 above.
; 1091 : 
; 1092 :   for (i = 0; i < newwidth; i += 2)

	xor	ebp, ebp
	push	esi
	push	edi
	cmp	DWORD PTR [ecx], ebp
	jle	$LN3@InitTables
	xor	ebx, ebx
	mov	DWORD PTR tv683[esp+20], 256		; 00000100H
	npad	7
$LL4@InitTables:

; 1093 :   {
; 1094 :     // first make even pixel control
; 1095 :     j = i * 256 * (oldwidth) / (newwidth)+(128 * oldwidth) / newwidth - 128;//  wrong scale fixed by Fizick

	mov	eax, DWORD PTR [ecx+8]
	imul	eax, ebp

; 1096 :     if (j < 0) j = 0; // added by Fizick
; 1097 : 
; 1098 :     k = j >> 8;
; 1099 :     wY2 = j - (k << 8);				// luma weight of right pixel
; 1100 :     wY1 = 256 - wY2;				// luma weight of left pixel
; 1101 : 
; 1102 :     if (k > oldwidth - 2)

	mov	edi, DWORD PTR [ecx+8]
	shl	eax, 8
	cdq
	idiv	DWORD PTR [ecx]
	mov	esi, eax
	mov	eax, DWORD PTR [ecx+8]
	shl	eax, 7
	cdq
	idiv	DWORD PTR [ecx]
	add	eax, -128				; ffffff80H
	add	eax, esi
	xor	esi, esi
	test	eax, eax
	cmovns	esi, eax
	mov	edx, esi
	sar	edx, 8
	mov	eax, edx
	shl	eax, 8
	sub	esi, eax
	lea	eax, DWORD PTR [edi-2]
	cmp	edx, eax

; 1103 :     {
; 1104 :       hControl[i * 3 + 4] = oldwidth - 1;	 //	point to last byte

	mov	eax, DWORD PTR [ecx+16]
	jle	SHORT $LN9@InitTables
	lea	edx, DWORD PTR [edi-1]
	mov	DWORD PTR [ebx+eax+16], edx

; 1105 :       hControl[i * 3] = 0x00000100;    // use 100% of rightmost Y

	mov	eax, DWORD PTR [ecx+16]
	mov	DWORD PTR [ebx+eax], 256		; 00000100H

; 1106 :     }
; 1107 :     else

	jmp	SHORT $LN10@InitTables
$LN9@InitTables:

; 1108 :     {
; 1109 :       hControl[i * 3 + 4] = k;			// pixel offset

	mov	DWORD PTR [ebx+eax+16], edx
	mov	edx, 256				; 00000100H

; 1110 :       hControl[i * 3] = wY2 << 16 | wY1; // luma weights

	mov	eax, DWORD PTR [ecx+16]
	sub	edx, esi
	shl	esi, 16					; 00000010H
	or	edx, esi
	mov	DWORD PTR [ebx+eax], edx
$LN10@InitTables:

; 1111 :     }
; 1112 : 
; 1113 :     // now make odd pixel control
; 1114 :     j = (i + 1) * 256 * (oldwidth) / (newwidth)+(128 * oldwidth) / newwidth - 128;// wrong scale fixed by Fizick - 

	mov	eax, DWORD PTR tv683[esp+20]
	imul	eax, DWORD PTR [ecx+8]

; 1115 :     if (j < 0) j = 0; // added by Fizick
; 1116 : 
; 1117 :     k = j >> 8;
; 1118 :     wY2 = j - (k << 8);				// luma weight of right pixel
; 1119 :     wY1 = 256 - wY2;				// luma weight of left pixel
; 1120 : 
; 1121 :     if (k > oldwidth - 2)

	mov	edi, DWORD PTR [ecx+8]
	cdq
	idiv	DWORD PTR [ecx]
	mov	esi, eax
	mov	eax, DWORD PTR [ecx+8]
	shl	eax, 7
	add	esi, -128				; ffffff80H
	cdq
	idiv	DWORD PTR [ecx]
	add	eax, esi
	xor	esi, esi
	test	eax, eax
	cmovns	esi, eax
	mov	edx, esi
	sar	edx, 8
	mov	eax, edx
	shl	eax, 8
	sub	esi, eax
	lea	eax, DWORD PTR [edi-2]
	cmp	edx, eax

; 1122 :     {
; 1123 :       hControl[i * 3 + 5] = oldwidth - 1;	 //	point to last byte

	mov	eax, DWORD PTR [ecx+16]
	jle	SHORT $LN12@InitTables
	lea	edx, DWORD PTR [edi-1]
	mov	DWORD PTR [ebx+eax+20], edx

; 1124 :       hControl[i * 3 + 1] = 0x00000100;    // use 100% of rightmost Y

	mov	eax, DWORD PTR [ecx+16]
	mov	DWORD PTR [ebx+eax+4], 256		; 00000100H

; 1125 :     }
; 1126 :     else

	jmp	SHORT $LN2@InitTables
$LN12@InitTables:

; 1127 :     {
; 1128 :       hControl[i * 3 + 5] = k;			// pixel offset

	mov	DWORD PTR [ebx+eax+20], edx
	mov	edx, 256				; 00000100H

; 1129 :       hControl[i * 3 + 1] = wY2 << 16 | wY1; // luma weights

	mov	eax, DWORD PTR [ecx+16]
	sub	edx, esi
	shl	esi, 16					; 00000010H
	or	edx, esi
	mov	DWORD PTR [ebx+eax+4], edx
$LN2@InitTables:

; 1081 :   int i;
; 1082 :   int j;
; 1083 :   int k;
; 1084 :   int wY1;
; 1085 :   int wY2;
; 1086 : 
; 1087 :   // First set up horizontal table, use for both luma & chroma since 
; 1088 :   // it seems to have the same equation.
; 1089 :   // We will geneerate these values in pairs, mostly because that's the way
; 1090 :   // I wrote it for YUY2 above.
; 1091 : 
; 1092 :   for (i = 0; i < newwidth; i += 2)

	add	DWORD PTR tv683[esp+20], 512		; 00000200H
	add	ebp, 2
	add	ebx, 24					; 00000018H
	cmp	ebp, DWORD PTR [ecx]
	jl	$LL4@InitTables
$LN3@InitTables:

; 1130 :     }
; 1131 :   }
; 1132 : 
; 1133 :   hControl[newwidth * 3 + 4] = 2 * (oldwidth - 1);		// give it something to prefetch at end

	mov	eax, DWORD PTR [ecx+8]

; 1134 :   hControl[newwidth * 3 + 5] = 2 * (oldwidth - 1);		// "
; 1135 : 
; 1136 :   // Next set up vertical tables. The offsets are measured in lines and will be mult
; 1137 :   // by the source pitch later .
; 1138 : 
; 1139 :   // For YV12 we need separate Luma and chroma tables
; 1140 :   // First Luma Table
; 1141 : 
; 1142 :   for (i = 0; i < newheight; ++i)

	xor	ebx, ebx
	lea	esi, DWORD PTR [eax*2-2]
	mov	eax, DWORD PTR [ecx]
	lea	edx, DWORD PTR [eax+eax*2]
	mov	eax, DWORD PTR [ecx+16]
	mov	DWORD PTR [eax+edx*4+16], esi
	mov	eax, DWORD PTR [ecx+8]
	lea	esi, DWORD PTR [eax*2-2]
	mov	eax, DWORD PTR [ecx]
	lea	edx, DWORD PTR [eax+eax*2]
	mov	eax, DWORD PTR [ecx+16]
	mov	DWORD PTR [eax+edx*4+20], esi
	cmp	DWORD PTR [ecx+4], ebx
	jle	SHORT $LN6@InitTables
$LL7@InitTables:

; 1143 :   {
; 1144 :     j = i * 256 * (oldheight) / (newheight)+(128 * oldheight) / newheight - 128; // Fizick

	mov	ebp, DWORD PTR [ecx+12]
	mov	eax, ebp
	imul	eax, ebx
	shl	eax, 8
	cdq
	idiv	DWORD PTR [ecx+4]
	mov	esi, eax
	mov	eax, ebp
	shl	eax, 7
	cdq
	idiv	DWORD PTR [ecx+4]
	xor	edx, edx
	add	eax, -128				; ffffff80H
	add	eax, esi
	cmovns	edx, eax

; 1145 :     if (j < 0) j = 0; // added by Fizick
; 1146 : 
; 1147 :     k = j >> 8;
; 1148 :     if (k > oldheight - 2) { k = oldheight - 1; j = k << 8; } // added by Fizick

	lea	eax, DWORD PTR [ebp-2]
	mov	esi, edx
	sar	esi, 8
	cmp	esi, eax
	jle	SHORT $LN15@InitTables
	lea	esi, DWORD PTR [ebp-1]
	mov	edx, esi
	shl	edx, 8
$LN15@InitTables:

; 1149 :     vOffsets[i] = k;

	mov	eax, DWORD PTR [ecx+20]
	mov	DWORD PTR [eax+ebx*4], esi

; 1150 :     wY2 = j - (k << 8);
; 1151 :     vWeights[i] = wY2;				// weight to give to 2nd line

	mov	eax, DWORD PTR [ecx+24]
	shl	esi, 8
	sub	edx, esi
	mov	DWORD PTR [eax+ebx*4], edx
	inc	ebx
	cmp	ebx, DWORD PTR [ecx+4]
	jl	SHORT $LL7@InitTables
$LN6@InitTables:
	pop	edi
	pop	esi
	pop	ebp
	pop	ebx

; 1152 :   }
; 1153 : }

	pop	ecx
	ret	0
?InitTables@SimpleResize@@AAEXXZ ENDP			; SimpleResize::InitTables
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File c:\github\mvtools\sources\simpleresize.cpp
;	COMDAT ??$SimpleResizeDo_New@E@SimpleResize@@QAEXPAEHHHPBEHH@Z
_TEXT	SEGMENT
_vWorkYW$1$ = -52					; size = 4
_row_size_mod4$1$ = -48					; size = 4
_pControl$1$ = -44					; size = 4
_y$1$ = -40						; size = 4
_mod8or16w$1$ = -36					; size = 4
_x$1$ = -32						; size = 4
_x$1$ = -32						; size = 4
tv1996 = -32						; size = 4
_vOffsetsW$1$ = -28					; size = 4
tv2012 = -24						; size = 4
tv2005 = -20						; size = 4
tv1994 = -20						; size = 4
tv2002 = -16						; size = 4
tv1997 = -16						; size = 4
tv1993 = -16						; size = 4
_invCurrentWeight$1$ = -12				; size = 4
tv2003 = -12						; size = 4
_CurrentWeight$1$ = -8					; size = 4
tv2010 = -8						; size = 4
tv2006 = -8						; size = 4
_vWeightsW$1$ = -4					; size = 4
_dstp8$ = 8						; size = 4
_row_size$ = 12						; size = 4
_height$ = 16						; size = 4
_dst_pitch$ = 20					; size = 4
_srcp8$ = 24						; size = 4
_src_row_size$ = 28					; size = 4
_src_pitch$ = 32					; size = 4
??$SimpleResizeDo_New@E@SimpleResize@@QAEXPAEHHHPBEHH@Z PROC ; SimpleResize::SimpleResizeDo_New<unsigned char>, COMDAT
; _this$ = ecx

; 116  : {

	push	ebp
	mov	ebp, esp
	and	esp, -8					; fffffff8H
	sub	esp, 56					; 00000038H

; 117  :   src_type *dstp = reinterpret_cast<src_type *>(dstp8);
; 118  :   const src_type *srcp = reinterpret_cast<const src_type *>(srcp8);
; 119  :   // Note: PlanarType is dummy, I (Fizick) do not use croma planes code for resize in MVTools
; 120  :   /*
; 121  :   SetMemoryMax(6000)
; 122  :   a=Avisource("c:\tape13\Videos\Tape02_digitall_Hi8.avi").assumefps(25,1).trim(0, 499)
; 123  :   a=a.AssumeBFF()
; 124  :   a=a.QTGMC(Preset="Slower",dct=5, ChromaMotion=true)
; 125  :   sup = a.MSuper(pel=1)
; 126  :   fw = sup.MAnalyse(isb=false, delta=1, overlap=4)
; 127  :   bw = sup.MAnalyse(isb=true, delta=1, overlap=4)
; 128  :   a=a.MFlowInter(sup, bw, fw, time=50, thSCD1=400) # MFlowInter uses SimpleResize
; 129  :   a
; 130  :   */
; 131  :   typedef src_type workY_type; // be the same
; 132  :   const unsigned int* pControl = &hControl[0];

	mov	eax, DWORD PTR [ecx+16]

; 133  : 
; 134  :   const src_type * srcp1;
; 135  :   const src_type * srcp2;
; 136  :   workY_type * vWorkYW = sizeof(workY_type) == 1 ? (workY_type *)vWorkY : (workY_type *)vWorkY2;

	mov	edx, DWORD PTR [ecx+28]
	push	esi

; 137  : 
; 138  :   unsigned int* vOffsetsW = vOffsets;

	mov	esi, DWORD PTR [ecx+20]
	mov	DWORD PTR _pControl$1$[esp+60], eax

; 139  :   unsigned int* vWeightsW = vWeights;
; 140  : 
; 141  :   for (int y = 0; y < height; y++)

	mov	eax, DWORD PTR _height$[ebp]
	mov	DWORD PTR _vWorkYW$1$[esp+60], edx
	mov	DWORD PTR _vOffsetsW$1$[esp+60], esi
	mov	DWORD PTR _y$1$[esp+60], 0
	push	edi
	mov	edi, DWORD PTR [ecx+24]
	test	eax, eax
	jle	$LN3@SimpleResi

; 147  : 
; 148  :     // scrp2 is the next line (check for the most bottom line)
; 149  :     srcp2 = (y < height - 1) ? srcp1 + src_pitch : srcp1; // pitch is uchar/short-aware
; 150  : 
; 151  :     int mod8or16w = src_row_size / (16 / sizeof(workY_type)) * (16 / sizeof(workY_type));
; 152  :     __m128i FPround1 = _mm_set1_epi16(0x0080);

	movaps	xmm7, XMMWORD PTR __xmm@00800080008000800080008000800080
	dec	eax
	mov	DWORD PTR tv2012[esp+64], eax
	xorps	xmm4, xmm4
	mov	eax, DWORD PTR _src_row_size$[ebp]
	and	eax, -16				; fffffff0H
	mov	DWORD PTR _mod8or16w$1$[esp+64], eax
	mov	eax, DWORD PTR _row_size$[ebp]
	and	eax, -4					; fffffffcH
	sub	edi, esi
	mov	DWORD PTR _row_size_mod4$1$[esp+64], eax
	mov	DWORD PTR _vWeightsW$1$[esp+64], edi
	npad	1
$LL4@SimpleResi:

; 142  :   {
; 143  :     int CurrentWeight = vWeightsW[y];
; 144  :     int invCurrentWeight = 256 - CurrentWeight;

	mov	ecx, DWORD PTR [edi+esi]
	mov	eax, 256				; 00000100H

; 145  : 
; 146  :     srcp1 = srcp + vOffsetsW[y] * src_pitch;

	mov	esi, DWORD PTR [esi]
	sub	eax, ecx
	mov	edi, DWORD PTR _src_pitch$[ebp]
	mov	edx, DWORD PTR tv2012[esp+64]
	imul	esi, edi
	mov	DWORD PTR _invCurrentWeight$1$[esp+64], eax

; 153  :     __m128i FPround2 = _mm_set1_epi32(0x0080);
; 154  :     // weights are 0..255 and (8 bit scaled) , rounding is 128 (0.5)
; 155  :     __m128i weight1 = _mm_set1_epi16(invCurrentWeight); // _mm_loadu_si128(reinterpret_cast<const __m128i *>(vWeight1));

	cwde
	mov	DWORD PTR _CurrentWeight$1$[esp+64], ecx
	add	esi, DWORD PTR _srcp8$[ebp]
	movd	xmm0, eax
	add	edi, esi
	cmp	DWORD PTR _y$1$[esp+64], edx

; 156  :     __m128i weight2 = _mm_set1_epi16(CurrentWeight);    // _mm_loadu_si128(reinterpret_cast<const __m128i *>(vWeight2));
; 157  :     __m128i zero = _mm_setzero_si128();
; 158  :     for (int x = 0; x < src_row_size; x += (16 / sizeof(workY_type))) {

	mov	edx, DWORD PTR _vWorkYW$1$[esp+64]
	movsx	eax, cx
	cmovge	edi, esi
	mov	ecx, DWORD PTR _src_row_size$[ebp]
	punpcklwd xmm0, xmm0
	pshufd	xmm5, xmm0, 0
	movd	xmm0, eax
	punpcklwd xmm0, xmm0
	mov	DWORD PTR tv1997[esp+64], edi
	pshufd	xmm6, xmm0, 0
	test	ecx, ecx
	jle	$LN6@SimpleResi
	mov	ecx, esi
	sub	edx, edi
	sub	ecx, edi
	mov	DWORD PTR tv1994[esp+64], edx
	mov	DWORD PTR tv1996[esp+64], ecx
	mov	eax, edi
	mov	ecx, DWORD PTR _src_row_size$[ebp]
	mov	edx, DWORD PTR tv1996[esp+64]
	dec	ecx
	mov	edi, DWORD PTR tv1994[esp+64]
	shr	ecx, 4
	inc	ecx
	npad	5
$LL7@SimpleResi:
	lea	eax, DWORD PTR [eax+16]

; 159  :       // top of 2 lines to interpolate
; 160  :       // load or loadu?
; 161  :       __m128i src1, src2, result;
; 162  :       if (sizeof(src_type) == 1 && sizeof(workY_type) == 2) {
; 163  :         src1 = _mm_loadl_epi64(reinterpret_cast<const __m128i *>((src_type *)srcp1 + x));
; 164  :         src2 = _mm_loadl_epi64(reinterpret_cast<const __m128i *>((src_type *)srcp2 + x)); // 2nd of 2 lines
; 165  :         src1 = _mm_unpacklo_epi8(src1, zero); // make words
; 166  :         src2 = _mm_unpackhi_epi8(src2, zero);
; 167  :         // we have 8 words 
; 168  :       }
; 169  :       else {
; 170  :         // unaligned! src_pitch is not 16 byte friendly
; 171  :         src1 = _mm_loadu_si128(reinterpret_cast<const __m128i *>((src_type *)srcp1 + x));

	movups	xmm2, XMMWORD PTR [eax+edx-16]

; 172  :         src2 = _mm_loadu_si128(reinterpret_cast<const __m128i *>((src_type *)srcp2 + x)); // 2nd of 2 lines

	movups	xmm3, XMMWORD PTR [eax-16]

; 173  :       }
; 174  :       if (sizeof(src_type) == 1 && sizeof(workY_type) == 1) {
; 175  :         __m128i src1_lo = _mm_unpacklo_epi8(src1, zero); // make words

	movaps	xmm0, xmm2

; 176  :         __m128i src1_hi = _mm_unpackhi_epi8(src1, zero);

	punpckhbw xmm2, xmm4
	punpcklbw xmm0, xmm4

; 177  :         __m128i src2_lo = _mm_unpacklo_epi8(src2, zero);

	movaps	xmm1, xmm3
	punpcklbw xmm1, xmm4

; 178  :         __m128i src2_hi = _mm_unpackhi_epi8(src2, zero);

	punpckhbw xmm3, xmm4

; 179  : 
; 180  :         __m128i res1_lo = _mm_mullo_epi16(src1_lo, weight1); // mult by weighting factor 1
; 181  :         __m128i res1_hi = _mm_mullo_epi16(src1_hi, weight1); // mult by weighting factor 1
; 182  :         __m128i res2_lo = _mm_mullo_epi16(src2_lo, weight2); // mult by weighting factor 2

	pmullw	xmm1, xmm6

; 183  :         __m128i res2_hi = _mm_mullo_epi16(src2_hi, weight2); // mult by weighting factor 2

	pmullw	xmm3, xmm6
	pmullw	xmm0, xmm5
	pmullw	xmm2, xmm5

; 184  :         __m128i res_lo = _mm_srli_epi16(_mm_adds_epu16(_mm_add_epi16(res1_lo, res2_lo), FPround1), 8); // combine lumas low + round and right adjust luma

	paddw	xmm1, xmm0

; 185  :         __m128i res_hi = _mm_srli_epi16(_mm_adds_epu16(_mm_add_epi16(res1_hi, res2_hi), FPround1), 8); // combine lumas high + round and right

	paddw	xmm3, xmm2
	paddusw	xmm1, xmm7
	psrlw	xmm1, 8
	paddusw	xmm3, xmm7
	psrlw	xmm3, 8

; 186  :         result = _mm_packus_epi16(res_lo, res_hi);// pack words to our 16 byte answer

	packuswb xmm1, xmm3

; 187  :       }
; 188  :       else {
; 189  :      // workY_type == short
; 190  :         __m128i res1_lo = _mm_mullo_epi16(src1, weight1); // mult by weighting factor 1
; 191  :         __m128i res1_hi = _mm_mulhi_epi16(src1, weight1); // upper 32 bits of src1 * weight
; 192  :         __m128i res2_lo = _mm_mullo_epi16(src2, weight2); // mult by weighting factor 2
; 193  :         __m128i res2_hi = _mm_mulhi_epi16(src2, weight2); // upper 32 bits of src2 * weight
; 194  :                                                           // combine 16lo 16hi results to 32 bit result
; 195  :         __m128i mulres1_lo = _mm_unpacklo_epi16(res1_lo, res1_hi); //  src1 0..3   4x32 bit result of multiplication as 32 bit
; 196  :         __m128i mulres1_hi = _mm_unpackhi_epi16(res1_lo, res1_hi); //       4..7   4x32 bit result of multiplication as 32 bit
; 197  :         __m128i mulres2_lo = _mm_unpacklo_epi16(res2_lo, res2_hi); //  src2 0..3   4x32 bit result of multiplication as 32 bit
; 198  :         __m128i mulres2_hi = _mm_unpackhi_epi16(res2_lo, res2_hi); //       4..7   4x32 bit result of multiplication as 32 bit
; 199  : 
; 200  :         __m128i res_lo = _mm_srai_epi32(_mm_add_epi32(_mm_add_epi32(mulres1_lo, mulres2_lo), FPround2), 8); // combine lumas + dword rounder 0x00000080
; 201  :         __m128i res_hi = _mm_srai_epi32(_mm_add_epi32(_mm_add_epi32(mulres1_hi, mulres2_hi), FPround2), 8); // combine lumas + dword rounder 0x00000080;
; 202  : 
; 203  :         result = _mm_packs_epi32(res_lo, res_hi); // pack into 8 words
; 204  :       }
; 205  :       // workY is well aligned (even 128 bytes)
; 206  :       _mm_stream_si128(reinterpret_cast<__m128i *>((workY_type *)vWorkYW + x), result); // movntdq don't pollute cache

	movntdq	XMMWORD PTR [eax+edi-16], xmm1
	sub	ecx, 1
	jne	SHORT $LL7@SimpleResi
	mov	edi, DWORD PTR tv1997[esp+64]
	mov	ecx, DWORD PTR _src_row_size$[ebp]
$LN6@SimpleResi:

; 207  :     }
; 208  :     // the rest one-by-one
; 209  :     for (int x = mod8or16w; x < src_row_size; x++) {

	mov	eax, DWORD PTR _mod8or16w$1$[esp+64]
	cmp	eax, ecx
	jge	SHORT $LN9@SimpleResi
	lea	edx, DWORD PTR [edi+eax]
	sub	esi, edi
	mov	eax, DWORD PTR _vWorkYW$1$[esp+64]
	sub	eax, edi
	mov	edi, ecx
	sub	edi, DWORD PTR _mod8or16w$1$[esp+64]
	mov	DWORD PTR tv1993[esp+64], eax
	npad	1
$LL10@SimpleResi:

; 210  :       vWorkYW[x] = (srcp1[x] * invCurrentWeight + srcp2[x] * CurrentWeight + 128) >> 8;

	movzx	ecx, BYTE PTR [edx+esi]
	lea	edx, DWORD PTR [edx+1]
	imul	ecx, DWORD PTR _invCurrentWeight$1$[esp+64]
	movzx	eax, BYTE PTR [edx-1]
	imul	eax, DWORD PTR _CurrentWeight$1$[esp+64]
	sub	ecx, -128				; ffffff80H
	add	eax, ecx
	mov	ecx, DWORD PTR tv1993[esp+64]
	sar	eax, 8
	mov	BYTE PTR [edx+ecx-1], al
	sub	edi, 1
	jne	SHORT $LL10@SimpleResi
$LN9@SimpleResi:

; 218  :     for (int x = 0; x < row_size_mod4; x += 4) {

	mov	eax, DWORD PTR _row_size_mod4$1$[esp+64]
	mov	esi, DWORD PTR _vWorkYW$1$[esp+64]
	mov	DWORD PTR _x$1$[esp+64], 0
	test	eax, eax
	jle	$LN12@SimpleResi

; 211  :     }
; 212  : 
; 213  :     // We've taken care of the vertical scaling, now do horizontal
; 214  :     // rework
; 215  :     // We've taken care of the vertical scaling, now do horizontal
; 216  :     // vvv for src_type char it can be loop by 8
; 217  :     int row_size_mod4 = row_size & ~3;

	mov	ecx, DWORD PTR _pControl$1$[esp+64]
	mov	eax, -16				; fffffff0H
	movaps	xmm5, XMMWORD PTR __xmm@00000080000000800000008000000080
	sub	eax, ecx
	mov	DWORD PTR tv2005[esp+64], eax
	lea	edi, DWORD PTR [ecx+16]
	npad	5
$LL13@SimpleResi:

; 219  : #ifdef USE_SSE2_HORIZONTAL_HELPERS        
; 220  :       unsigned int pc0, pc1, pc2, pc3;
; 221  :       short b0, b1, b2, b3, b4, b5, b6, b7;
; 222  : #endif
; 223  :       unsigned int offs0, offs1, offs2, offs3;
; 224  : 
; 225  :       // mov		eax, [rsi + 16]
; 226  :       offs0 = pControl[3 * x + 4];   // get data offset in pixels, 1st pixel pair. Control[4]=offs
; 227  :                                      // mov		ebx, [rsi + 20]
; 228  :       offs1 = pControl[3 * x + 5];   // get data offset in pixels, 2nd pixel pair. Control[5]=offsodd
; 229  : 
; 230  :       offs2 = pControl[3 * x + 4 + (2 * 3)];   // get data offset in pixels, 3nd pixel pair. Control[5]=offsodd
; 231  :       offs3 = pControl[3 * x + 5 + (2 * 3)];   // get data offset in pixels, 4nd pixel pair. Control[5]=offsodd
; 232  : 
; 233  :                                              /*source_t*/
; 234  :                                              // (uint32_t)pair1     = (uint32_t *)((short *)(vWorkYW)[offs])      // vWorkYW[offs] and vWorkYW[offs+1]
; 235  :                                              // (uint32_t)pair2odds = (uint32_t *)((short *)(vWorkYW)[offsodds])  // vWorkYW[offsodds] and vWorkYW[offsodds+1]
; 236  :       __m128i a_pair3210;
; 237  :       uint32_t pair0, pair1, pair2, pair3;
; 238  :       if (sizeof(workY_type) == 1) { // vWorkYW uchars
; 239  :         uint16_t pair0_2x8 = *(uint16_t *)(&vWorkYW[offs0]);      // vWorkYW[offs] and vWorkYW[offs+1]
; 240  :         uint16_t pair1_2x8 = *(uint16_t *)(&vWorkYW[offs1]);      // vWorkYW[offs] and vWorkYW[offs+1]
; 241  :         uint16_t pair2_2x8 = *(uint16_t *)(&vWorkYW[offs2]);      // vWorkYW[offs] and vWorkYW[offs+1]
; 242  :         uint16_t pair3_2x8 = *(uint16_t *)(&vWorkYW[offs3]);      // vWorkYW[offs] and vWorkYW[offs+1]
; 243  :         pair0 = (((uint32_t)pair0_2x8 & 0xFF00) << 8) + (pair0_2x8 & 0xFF);
; 244  :         pair1 = (((uint32_t)pair1_2x8 & 0xFF00) << 8) + (pair1_2x8 & 0xFF);
; 245  :         pair2 = (((uint32_t)pair2_2x8 & 0xFF00) << 8) + (pair2_2x8 & 0xFF);
; 246  :         pair3 = (((uint32_t)pair3_2x8 & 0xFF00) << 8) + (pair3_2x8 & 0xFF);
; 247  :         __m128i a_pair10 = _mm_or_si128(_mm_shuffle_epi32(_mm_cvtsi32_si128(pair1), _MM_SHUFFLE(0, 0, 0, 1)), _mm_cvtsi32_si128(pair0));
; 248  :         __m128i a_pair32 = _mm_or_si128(_mm_shuffle_epi32(_mm_cvtsi32_si128(pair3), _MM_SHUFFLE(0, 0, 0, 1)), _mm_cvtsi32_si128(pair2));
; 249  :         a_pair3210 = _mm_unpacklo_epi64(a_pair10, a_pair32);
; 250  : 
; 251  :       }
; 252  :       else { // vWorkYW shorts
; 253  :         pair0 = *(uint32_t *)(&vWorkYW[offs0]);      // vWorkYW[offs] and vWorkYW[offs+1]
; 254  :         pair1 = *(uint32_t *)(&vWorkYW[offs1]);      // vWorkYW[offs] and vWorkYW[offs+1]
; 255  :         pair2 = *(uint32_t *)(&vWorkYW[offs2]);      // vWorkYW[offs] and vWorkYW[offs+1]
; 256  :         pair3 = *(uint32_t *)(&vWorkYW[offs3]);      // vWorkYW[offs] and vWorkYW[offs+1]
; 257  :         __m128i a_pair10 = _mm_or_si128(_mm_shuffle_epi32(_mm_cvtsi32_si128(pair1), _MM_SHUFFLE(0, 0, 0, 1)), _mm_cvtsi32_si128(pair0));
; 258  :         __m128i a_pair32 = _mm_or_si128(_mm_shuffle_epi32(_mm_cvtsi32_si128(pair3), _MM_SHUFFLE(0, 0, 0, 1)), _mm_cvtsi32_si128(pair2));
; 259  :         a_pair3210 = _mm_unpacklo_epi64(a_pair10, a_pair32);
; 260  :       }
; 261  : 
; 262  : #ifdef USE_SSE2_HORIZONTAL_HELPERS        
; 263  :       pc0 = pControl[3 * x + 0];         // uint32: Y2_0:Y1_0
; 264  :       pc1 = pControl[3 * x + 1];         // uint32: Y2_1:Y1_1 
; 265  :       pc2 = pControl[3 * x + 0 + (2 * 3)]; // uint32: Y2_2:Y1_2 
; 266  :       pc3 = pControl[3 * x + 1 + (2 * 3)]; // uint32: Y2_3:Y1_3 
; 267  : #endif
; 268  : 
; 269  :       // pc1, pc0
; 270  :       __m128i b_pair10 = _mm_loadl_epi64(reinterpret_cast<const __m128i*>(&pControl[3 * x + 0])); // +0, +1
; 271  :       // load the lower 64 bits from (unaligned)
; 272  :       // pc3, pc2
; 273  :       __m128i b_pair3210 = _mm_castpd_si128(_mm_loadh_pd(_mm_castsi128_pd(b_pair10), reinterpret_cast<const double*>(&pControl[3 * x + 0 + (2 * 3)])));

	add	eax, ecx
	movq	xmm3, QWORD PTR [edi-16]
	lea	edi, DWORD PTR [edi+48]
	movhpd	xmm3, QWORD PTR [eax+edi-24]

; 274  :       // load the higher 64 bits from 2nd param, lower 64 bit copied from 1st param
; 275  : 
; 276  : #ifdef USE_SSE2_HORIZONTAL_HELPERS        
; 277  :       unsigned int wY1_0 = b0 = pc0 & 0x0000ffff; //low
; 278  :       unsigned int wY2_0 = b1 = pc0 >> 16; //high
; 279  :       unsigned int wY1_1 = b2 = pc1 & 0x0000ffff; //low
; 280  :       unsigned int wY2_1 = b3 = pc1 >> 16; //high
; 281  :       unsigned int wY1_2 = b4 = pc2 & 0x0000ffff; //low
; 282  :       unsigned int wY2_2 = b5 = pc2 >> 16; //high
; 283  :       unsigned int wY1_3 = b6 = pc3 & 0x0000ffff; //low
; 284  :       unsigned int wY2_3 = b7 = pc3 >> 16; //high
; 285  :       short a0 = vWorkYW[offs0]; // 1 or 2 byte
; 286  :       short a1 = vWorkYW[offs0 + 1];
; 287  :       short a2 = vWorkYW[offs1];
; 288  :       short a3 = vWorkYW[offs1 + 1];
; 289  :       short a4 = vWorkYW[offs2];
; 290  :       short a5 = vWorkYW[offs2 + 1];
; 291  :       short a6 = vWorkYW[offs3];
; 292  :       short a7 = vWorkYW[offs3 + 1];
; 293  : 
; 294  :       BYTE res0 = (a0 * b0 + a1 * b1 + 128) >> 8;
; 295  :       BYTE res1 = (a2 * b2 + a3 * b3 + 128) >> 8;
; 296  :       BYTE res2 = (a4 * b4 + a5 * b5 + 128) >> 8;
; 297  :       BYTE res3 = (a6 * b6 + a7 * b7 + 128) >> 8;
; 298  :       BYTE cmp0 = dstp[x + 0];
; 299  :       BYTE cmp1 = dstp[x + 1];
; 300  :       BYTE cmp2 = dstp[x + 2];
; 301  :       BYTE cmp3 = dstp[x + 3];
; 302  :       /*
; 303  :       dstp[x+0] = res0;
; 304  :       dstp[x+1] = res1;
; 305  :       dstp[x+2] = res2;
; 306  :       dstp[x+3] = res3;
; 307  :       */
; 308  : #endif
; 309  :       // pmaddwd mm0, [rsi]			// mult and sum lumas by ctl weights. v1v0 Control[1] and w1w0 Control[0]
; 310  :       // __m128i _mm_madd_epi16 (__m128i a, __m128i b);
; 311  :       // PMADDWD
; 312  :       // r0 := (a0 * b0) + (a1 * b1)
; 313  :       // r1 := (a2 * b2) + (a3 * b3)
; 314  :       // r2 := (a4 * b4) + (a5 * b5)
; 315  :       // r3 := (a6 * b6) + (a7 * b7)
; 316  :       __m128i result = _mm_madd_epi16(a_pair3210, b_pair3210); // 4x integer
; 317  :       __m128i rounder = _mm_set1_epi32(0x0080);
; 318  :       result = _mm_add_epi32(result, rounder);
; 319  : 
; 320  :       if (sizeof(src_type) == 1)
; 321  :         result = _mm_srli_epi32(result, 8);

	mov	eax, DWORD PTR [edi-44]
	movzx	edx, WORD PTR [eax+esi]
	mov	eax, DWORD PTR [edi-48]
	mov	ecx, edx
	and	ecx, 65280				; 0000ff00H
	shl	ecx, 8
	movzx	eax, WORD PTR [eax+esi]
	mov	DWORD PTR tv2006[esp+64], eax
	mov	eax, DWORD PTR [edi-20]
	movzx	eax, WORD PTR [eax+esi]
	mov	DWORD PTR tv2003[esp+64], eax
	mov	eax, DWORD PTR [edi-24]
	movzx	eax, WORD PTR [eax+esi]
	mov	DWORD PTR tv2002[esp+64], eax
	movzx	eax, dl
	add	ecx, eax

; 322  :       else
; 323  :         result = _mm_srai_epi32(result, 8);  // 16 bit: arithmetic shift as in orig asm
; 324  :       result = _mm_packs_epi32(result, result); // 4xqword ->4xword
; 325  :       if (sizeof(src_type) == 1) {
; 326  :         // 8 bit version
; 327  :         result = _mm_packus_epi16(result, result); // 4xword ->4xbyte
; 328  :         uint32_t final4x8bitpixels = _mm_cvtsi128_si32(result);
; 329  :         *(uint32_t *)(&dstp[x]) = final4x8bitpixels;

	mov	edx, DWORD PTR _x$1$[esp+64]
	mov	eax, DWORD PTR tv2006[esp+64]
	movd	xmm0, ecx
	mov	ecx, eax
	and	ecx, 65280				; 0000ff00H
	movzx	eax, al
	shl	ecx, 8
	add	ecx, eax
	pshufd	xmm2, xmm0, 1
	mov	eax, DWORD PTR tv2003[esp+64]
	movd	xmm0, ecx
	mov	ecx, eax
	and	ecx, 65280				; 0000ff00H
	movzx	eax, al
	shl	ecx, 8
	por	xmm2, xmm0
	add	ecx, eax
	mov	eax, DWORD PTR tv2002[esp+64]
	movd	xmm0, ecx
	mov	ecx, eax
	and	ecx, 65280				; 0000ff00H
	movzx	eax, al
	shl	ecx, 8
	add	ecx, eax
	pshufd	xmm1, xmm0, 1
	mov	eax, DWORD PTR tv2005[esp+64]
	movd	xmm0, ecx
	mov	ecx, DWORD PTR _dstp8$[ebp]
	por	xmm1, xmm0
	punpcklqdq xmm2, xmm1
	pmaddwd	xmm2, xmm3
	paddd	xmm2, xmm5
	psrld	xmm2, 8
	packssdw xmm2, xmm2
	packuswb xmm2, xmm2
	movd	DWORD PTR [edx+ecx], xmm2
	add	edx, 4
	mov	ecx, DWORD PTR _pControl$1$[esp+64]
	mov	DWORD PTR _x$1$[esp+64], edx
	cmp	edx, DWORD PTR _row_size_mod4$1$[esp+64]
	jl	$LL13@SimpleResi
	mov	eax, DWORD PTR _row_size_mod4$1$[esp+64]
$LN12@SimpleResi:

; 330  :       }
; 331  :       else {
; 332  :         // for short version: 
; 333  :         _mm_storel_epi64(reinterpret_cast<__m128i *>(&dstp[x]), result);
; 334  :       }
; 335  :     }
; 336  :     // remaining
; 337  :     for (int x = row_size_mod4; x < row_size; x++) {

	mov	edx, eax
	mov	DWORD PTR _x$1$[esp+64], edx
	cmp	eax, DWORD PTR _row_size$[ebp]
	jge	SHORT $LN15@SimpleResi
	lea	ecx, DWORD PTR [esi+1]
	mov	esi, DWORD PTR _pControl$1$[esp+64]
	lea	eax, DWORD PTR [eax+eax*2]
	mov	DWORD PTR tv2010[esp+64], ecx
	lea	eax, DWORD PTR [eax-2]
	lea	eax, DWORD PTR [esi+eax*4]
$LL16@SimpleResi:

; 338  :       unsigned int pc;
; 339  :       unsigned int offs;
; 340  : 
; 341  :       if ((x & 1) == 0) { // even

	test	dl, 1
	jne	SHORT $LN27@SimpleResi

; 342  :         pc = pControl[3 * x];

	mov	esi, DWORD PTR [eax+8]

; 343  :         offs = pControl[3 * x + 4];

	mov	edi, DWORD PTR [eax+24]

; 344  :       }
; 345  :       else { // odd

	jmp	SHORT $LN28@SimpleResi
$LN27@SimpleResi:

; 346  :         pc = pControl[3 * x - 2]; // [3*xeven+1]

	mov	esi, DWORD PTR [eax]

; 347  :         offs = pControl[3 * x + 2]; // [3*xeven+5]

	mov	edi, DWORD PTR [eax+16]
$LN28@SimpleResi:

; 348  :       }
; 349  :       unsigned int wY1 = pc & 0x0000ffff; //low
; 350  :       unsigned int wY2 = pc >> 16; //high
; 351  :       dstp[x] = (vWorkYW[offs] * wY1 + vWorkYW[offs + 1] * wY2 + 128) >> 8;

	movzx	edx, BYTE PTR [ecx+edi]
	add	eax, 12					; 0000000cH
	mov	ecx, esi
	shr	ecx, 16					; 00000010H
	imul	edx, ecx
	mov	ecx, DWORD PTR _vWorkYW$1$[esp+64]
	movzx	ecx, BYTE PTR [edi+ecx]
	sub	edx, -128				; ffffff80H
	imul	ecx, esi
	mov	esi, DWORD PTR _dstp8$[ebp]
	add	ecx, edx
	mov	edx, DWORD PTR _x$1$[esp+64]
	shr	ecx, 8
	mov	BYTE PTR [edx+esi], cl
	inc	edx
	mov	ecx, DWORD PTR tv2010[esp+64]
	mov	DWORD PTR _x$1$[esp+64], edx
	cmp	edx, DWORD PTR _row_size$[ebp]
	jl	SHORT $LL16@SimpleResi
$LN15@SimpleResi:

; 352  :     }
; 353  :     // rework end
; 354  : 
; 355  :     dstp += dst_pitch;

	mov	eax, DWORD PTR _dst_pitch$[ebp]
	add	DWORD PTR _dstp8$[ebp], eax
	mov	eax, DWORD PTR _y$1$[esp+64]
	mov	esi, DWORD PTR _vOffsetsW$1$[esp+64]
	inc	eax
	mov	edi, DWORD PTR _vWeightsW$1$[esp+64]
	add	esi, 4
	mov	DWORD PTR _y$1$[esp+64], eax
	mov	DWORD PTR _vOffsetsW$1$[esp+64], esi
	cmp	eax, DWORD PTR _height$[ebp]
	jl	$LL4@SimpleResi
$LN3@SimpleResi:

; 356  : 
; 357  :   } // for y
; 358  : }

	pop	edi
	pop	esi
	mov	esp, ebp
	pop	ebp
	ret	28					; 0000001cH
??$SimpleResizeDo_New@E@SimpleResize@@QAEXPAEHHHPBEHH@Z ENDP ; SimpleResize::SimpleResizeDo_New<unsigned char>
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File c:\github\mvtools\sources\simpleresize.cpp
;	COMDAT ??$SimpleResizeDo_New@F@SimpleResize@@QAEXPAEHHHPBEHH@Z
_TEXT	SEGMENT
_vWorkYW$1$ = -108					; size = 4
_mod8or16w$1$ = -104					; size = 4
_srcp2$1$ = -100					; size = 4
_x$1$ = -96						; size = 4
tv2154 = -92						; size = 4
tv2139 = -92						; size = 4
tv2159 = -88						; size = 4
tv2158 = -88						; size = 4
tv2156 = -88						; size = 4
tv2137 = -88						; size = 4
_row_size_mod4$1$ = -84					; size = 4
_pControl$1$ = -80					; size = 4
_vWeightsW$1$ = -76					; size = 4
_srcp1$1$ = -72						; size = 4
_x$1$ = -68						; size = 4
_CurrentWeight$1$ = -68					; size = 4
tv2123 = -68						; size = 4
_y$1$ = -64						; size = 4
_vOffsetsW$1$ = -60					; size = 4
tv2169 = -56						; size = 4
tv2152 = -52						; size = 4
tv2076 = -52						; size = 4
tv2136 = -48						; size = 4
tv2151 = -44						; size = 4
tv2138 = -44						; size = 4
_invCurrentWeight$1$ = -40				; size = 4
tv2164 = -36						; size = 4
tv2173 = -32						; size = 16
tv2174 = -16						; size = 16
_dstp8$ = 8						; size = 4
_row_size$ = 12						; size = 4
_height$ = 16						; size = 4
_dst_pitch$ = 20					; size = 4
_srcp8$ = 24						; size = 4
_src_row_size$ = 28					; size = 4
_src_pitch$ = 32					; size = 4
??$SimpleResizeDo_New@F@SimpleResize@@QAEXPAEHHHPBEHH@Z PROC ; SimpleResize::SimpleResizeDo_New<short>, COMDAT
; _this$ = ecx

; 116  : {

	push	ebp
	mov	ebp, esp
	and	esp, -16				; fffffff0H
	sub	esp, 120				; 00000078H

; 117  :   src_type *dstp = reinterpret_cast<src_type *>(dstp8);
; 118  :   const src_type *srcp = reinterpret_cast<const src_type *>(srcp8);
; 119  :   // Note: PlanarType is dummy, I (Fizick) do not use croma planes code for resize in MVTools
; 120  :   /*
; 121  :   SetMemoryMax(6000)
; 122  :   a=Avisource("c:\tape13\Videos\Tape02_digitall_Hi8.avi").assumefps(25,1).trim(0, 499)
; 123  :   a=a.AssumeBFF()
; 124  :   a=a.QTGMC(Preset="Slower",dct=5, ChromaMotion=true)
; 125  :   sup = a.MSuper(pel=1)
; 126  :   fw = sup.MAnalyse(isb=false, delta=1, overlap=4)
; 127  :   bw = sup.MAnalyse(isb=true, delta=1, overlap=4)
; 128  :   a=a.MFlowInter(sup, bw, fw, time=50, thSCD1=400) # MFlowInter uses SimpleResize
; 129  :   a
; 130  :   */
; 131  :   typedef src_type workY_type; // be the same
; 132  :   const unsigned int* pControl = &hControl[0];

	mov	eax, DWORD PTR [ecx+16]
	push	esi

; 133  : 
; 134  :   const src_type * srcp1;
; 135  :   const src_type * srcp2;
; 136  :   workY_type * vWorkYW = sizeof(workY_type) == 1 ? (workY_type *)vWorkY : (workY_type *)vWorkY2;

	mov	esi, DWORD PTR [ecx+32]
	mov	DWORD PTR _pControl$1$[esp+124], eax

; 137  : 
; 138  :   unsigned int* vOffsetsW = vOffsets;
; 139  :   unsigned int* vWeightsW = vWeights;

	mov	eax, DWORD PTR [ecx+24]
	push	edi
	mov	edi, DWORD PTR [ecx+20]

; 140  : 
; 141  :   for (int y = 0; y < height; y++)

	xor	ecx, ecx
	mov	DWORD PTR _vWeightsW$1$[esp+128], eax
	mov	eax, DWORD PTR _height$[ebp]
	mov	DWORD PTR _vWorkYW$1$[esp+128], esi
	mov	DWORD PTR _vOffsetsW$1$[esp+128], edi
	mov	DWORD PTR _y$1$[esp+128], ecx
	test	eax, eax
	jle	$LN3@SimpleResi
	mov	edx, DWORD PTR _row_size$[ebp]
	dec	eax
	mov	DWORD PTR tv2169[esp+128], eax
	and	edx, -4					; fffffffcH
	mov	eax, DWORD PTR _src_row_size$[ebp]
	and	eax, -8					; fffffff8H
	mov	DWORD PTR _row_size_mod4$1$[esp+128], edx
	mov	DWORD PTR _mod8or16w$1$[esp+128], eax
	mov	eax, DWORD PTR _dst_pitch$[ebp]
	add	eax, eax
	mov	DWORD PTR tv2164[esp+128], eax
	mov	eax, DWORD PTR _vWeightsW$1$[esp+128]
	sub	eax, edi
	mov	DWORD PTR _vWeightsW$1$[esp+128], eax
$LL4@SimpleResi:

; 142  :   {
; 143  :     int CurrentWeight = vWeightsW[y];

	mov	eax, DWORD PTR [eax+edi]

; 144  :     int invCurrentWeight = 256 - CurrentWeight;

	mov	edx, 256				; 00000100H
	sub	edx, eax
	mov	DWORD PTR _CurrentWeight$1$[esp+128], eax
	mov	DWORD PTR _invCurrentWeight$1$[esp+128], edx
	movd	xmm0, eax

; 145  : 
; 146  :     srcp1 = srcp + vOffsetsW[y] * src_pitch;

	mov	eax, DWORD PTR [edi]
	imul	eax, DWORD PTR _src_pitch$[ebp]
	mov	edi, DWORD PTR _srcp8$[ebp]
	pshufd	xmm4, xmm0, 0
	movd	xmm0, edx
	pshufd	xmm5, xmm0, 0
	movaps	XMMWORD PTR tv2173[esp+128], xmm4
	movaps	XMMWORD PTR tv2174[esp+128], xmm5
	lea	edi, DWORD PTR [edi+eax*2]
	mov	DWORD PTR _srcp1$1$[esp+128], edi

; 147  : 
; 148  :     // scrp2 is the next line (check for the most bottom line)
; 149  :     srcp2 = (y < height - 1) ? srcp1 + src_pitch : srcp1; // pitch is uchar/short-aware

	cmp	ecx, DWORD PTR tv2169[esp+128]
	jge	SHORT $LN32@SimpleResi
	mov	eax, DWORD PTR _src_pitch$[ebp]
	lea	ecx, DWORD PTR [edi+eax*2]
	mov	DWORD PTR _srcp2$1$[esp+128], ecx
	jmp	SHORT $LN33@SimpleResi
$LN32@SimpleResi:
	mov	ecx, edi
	mov	DWORD PTR _srcp2$1$[esp+128], edi
$LN33@SimpleResi:

; 150  : 
; 151  :     int mod8or16w = src_row_size / (16 / sizeof(workY_type)) * (16 / sizeof(workY_type));
; 152  :     __m128i FPround1 = _mm_set1_epi16(0x0080);
; 153  :     __m128i FPround2 = _mm_set1_epi32(0x0080);
; 154  :     // weights are 0..255 and (8 bit scaled) , rounding is 128 (0.5)
; 155  :     __m128i weight1 = _mm_set1_epi16(invCurrentWeight); // _mm_loadu_si128(reinterpret_cast<const __m128i *>(vWeight1));

	movsx	eax, dx
	movd	xmm0, eax

; 156  :     __m128i weight2 = _mm_set1_epi16(CurrentWeight);    // _mm_loadu_si128(reinterpret_cast<const __m128i *>(vWeight2));

	mov	eax, DWORD PTR _CurrentWeight$1$[esp+128]
	cwde
	punpcklwd xmm0, xmm0
	pshufd	xmm6, xmm0, 0
	movd	xmm0, eax

; 157  :     __m128i zero = _mm_setzero_si128();
; 158  :     for (int x = 0; x < src_row_size; x += (16 / sizeof(workY_type))) {

	mov	eax, DWORD PTR _src_row_size$[ebp]
	punpcklwd xmm0, xmm0
	pshufd	xmm7, xmm0, 0
	test	eax, eax
	jle	$LN6@SimpleResi
	mov	eax, edi
	sub	esi, ecx
	sub	eax, ecx
	mov	DWORD PTR tv2139[esp+128], esi
	mov	edi, esi
	mov	edx, ecx
	mov	DWORD PTR tv2156[esp+128], eax
	mov	eax, DWORD PTR _src_row_size$[ebp]
	mov	esi, DWORD PTR tv2156[esp+128]
	dec	eax
	shr	eax, 3
	inc	eax
	npad	11
$LL7@SimpleResi:
	lea	edx, DWORD PTR [edx+16]

; 159  :       // top of 2 lines to interpolate
; 160  :       // load or loadu?
; 161  :       __m128i src1, src2, result;
; 162  :       if (sizeof(src_type) == 1 && sizeof(workY_type) == 2) {
; 163  :         src1 = _mm_loadl_epi64(reinterpret_cast<const __m128i *>((src_type *)srcp1 + x));
; 164  :         src2 = _mm_loadl_epi64(reinterpret_cast<const __m128i *>((src_type *)srcp2 + x)); // 2nd of 2 lines
; 165  :         src1 = _mm_unpacklo_epi8(src1, zero); // make words
; 166  :         src2 = _mm_unpackhi_epi8(src2, zero);
; 167  :         // we have 8 words 
; 168  :       }
; 169  :       else {
; 170  :         // unaligned! src_pitch is not 16 byte friendly
; 171  :         src1 = _mm_loadu_si128(reinterpret_cast<const __m128i *>((src_type *)srcp1 + x));

	movups	xmm5, XMMWORD PTR [esi+edx-16]

; 172  :         src2 = _mm_loadu_si128(reinterpret_cast<const __m128i *>((src_type *)srcp2 + x)); // 2nd of 2 lines

	movups	xmm3, XMMWORD PTR [edx-16]

; 173  :       }
; 174  :       if (sizeof(src_type) == 1 && sizeof(workY_type) == 1) {
; 175  :         __m128i src1_lo = _mm_unpacklo_epi8(src1, zero); // make words
; 176  :         __m128i src1_hi = _mm_unpackhi_epi8(src1, zero);
; 177  :         __m128i src2_lo = _mm_unpacklo_epi8(src2, zero);
; 178  :         __m128i src2_hi = _mm_unpackhi_epi8(src2, zero);
; 179  : 
; 180  :         __m128i res1_lo = _mm_mullo_epi16(src1_lo, weight1); // mult by weighting factor 1
; 181  :         __m128i res1_hi = _mm_mullo_epi16(src1_hi, weight1); // mult by weighting factor 1
; 182  :         __m128i res2_lo = _mm_mullo_epi16(src2_lo, weight2); // mult by weighting factor 2
; 183  :         __m128i res2_hi = _mm_mullo_epi16(src2_hi, weight2); // mult by weighting factor 2
; 184  :         __m128i res_lo = _mm_srli_epi16(_mm_adds_epu16(_mm_add_epi16(res1_lo, res2_lo), FPround1), 8); // combine lumas low + round and right adjust luma
; 185  :         __m128i res_hi = _mm_srli_epi16(_mm_adds_epu16(_mm_add_epi16(res1_hi, res2_hi), FPround1), 8); // combine lumas high + round and right
; 186  :         result = _mm_packus_epi16(res_lo, res_hi);// pack words to our 16 byte answer
; 187  :       }
; 188  :       else {
; 189  :      // workY_type == short
; 190  :         __m128i res1_lo = _mm_mullo_epi16(src1, weight1); // mult by weighting factor 1

	movaps	xmm4, xmm5

; 191  :         __m128i res1_hi = _mm_mulhi_epi16(src1, weight1); // upper 32 bits of src1 * weight

	pmulhw	xmm5, xmm6
	pmullw	xmm4, xmm6

; 192  :         __m128i res2_lo = _mm_mullo_epi16(src2, weight2); // mult by weighting factor 2

	movaps	xmm2, xmm3
	pmullw	xmm2, xmm7

; 193  :         __m128i res2_hi = _mm_mulhi_epi16(src2, weight2); // upper 32 bits of src2 * weight

	pmulhw	xmm3, xmm7

; 194  :                                                           // combine 16lo 16hi results to 32 bit result
; 195  :         __m128i mulres1_lo = _mm_unpacklo_epi16(res1_lo, res1_hi); //  src1 0..3   4x32 bit result of multiplication as 32 bit

	movaps	xmm0, xmm4

; 196  :         __m128i mulres1_hi = _mm_unpackhi_epi16(res1_lo, res1_hi); //       4..7   4x32 bit result of multiplication as 32 bit

	punpckhwd xmm4, xmm5
	punpcklwd xmm0, xmm5

; 197  :         __m128i mulres2_lo = _mm_unpacklo_epi16(res2_lo, res2_hi); //  src2 0..3   4x32 bit result of multiplication as 32 bit

	movaps	xmm1, xmm2
	punpcklwd xmm1, xmm3

; 198  :         __m128i mulres2_hi = _mm_unpackhi_epi16(res2_lo, res2_hi); //       4..7   4x32 bit result of multiplication as 32 bit

	punpckhwd xmm2, xmm3

; 199  : 
; 200  :         __m128i res_lo = _mm_srai_epi32(_mm_add_epi32(_mm_add_epi32(mulres1_lo, mulres2_lo), FPround2), 8); // combine lumas + dword rounder 0x00000080

	paddd	xmm1, xmm0
	paddd	xmm1, XMMWORD PTR __xmm@00000080000000800000008000000080

; 201  :         __m128i res_hi = _mm_srai_epi32(_mm_add_epi32(_mm_add_epi32(mulres1_hi, mulres2_hi), FPround2), 8); // combine lumas + dword rounder 0x00000080;

	paddd	xmm2, xmm4
	paddd	xmm2, XMMWORD PTR __xmm@00000080000000800000008000000080
	psrad	xmm1, 8
	psrad	xmm2, 8

; 202  : 
; 203  :         result = _mm_packs_epi32(res_lo, res_hi); // pack into 8 words

	packssdw xmm1, xmm2

; 204  :       }
; 205  :       // workY is well aligned (even 128 bytes)
; 206  :       _mm_stream_si128(reinterpret_cast<__m128i *>((workY_type *)vWorkYW + x), result); // movntdq don't pollute cache

	movntdq	XMMWORD PTR [edi+edx-16], xmm1
	sub	eax, 1
	jne	SHORT $LL7@SimpleResi
	movaps	xmm4, XMMWORD PTR tv2173[esp+128]
	movaps	xmm5, XMMWORD PTR tv2174[esp+128]
	mov	edi, DWORD PTR _srcp1$1$[esp+128]
	mov	esi, DWORD PTR _vWorkYW$1$[esp+128]
	mov	eax, DWORD PTR _src_row_size$[ebp]
$LN6@SimpleResi:

; 207  :     }
; 208  :     // the rest one-by-one
; 209  :     for (int x = mod8or16w; x < src_row_size; x++) {

	mov	ecx, DWORD PTR _mod8or16w$1$[esp+128]
	sub	eax, ecx
	cmp	ecx, DWORD PTR _src_row_size$[ebp]
	mov	edx, ecx
	mov	ecx, DWORD PTR _srcp2$1$[esp+128]
	mov	DWORD PTR _x$1$[esp+128], edx
	mov	DWORD PTR tv2076[esp+128], eax
	jge	$LN9@SimpleResi
	cmp	eax, 8
	jb	$LN45@SimpleResi

; 210  :       vWorkYW[x] = (srcp1[x] * invCurrentWeight + srcp2[x] * CurrentWeight + 128) >> 8;

	cmp	DWORD PTR ___isa_available, 2
	jl	$LN45@SimpleResi
	mov	eax, edx
	mov	edx, DWORD PTR _src_row_size$[ebp]
	dec	edx
	lea	eax, DWORD PTR [esi+eax*2]
	mov	esi, DWORD PTR _mod8or16w$1$[esp+128]
	mov	DWORD PTR tv2154[esp+128], eax
	lea	eax, DWORD PTR [ecx+esi*2]
	mov	esi, DWORD PTR _vWorkYW$1$[esp+128]
	mov	DWORD PTR tv2159[esp+128], eax
	lea	eax, DWORD PTR [ecx+edx*2]
	mov	edx, DWORD PTR _x$1$[esp+128]
	cmp	DWORD PTR tv2154[esp+128], eax
	ja	SHORT $LN46@SimpleResi
	mov	ecx, DWORD PTR _src_row_size$[ebp]
	dec	ecx
	lea	eax, DWORD PTR [esi+ecx*2]
	mov	ecx, DWORD PTR _srcp2$1$[esp+128]
	cmp	eax, DWORD PTR tv2159[esp+128]
	jae	$LN45@SimpleResi
$LN46@SimpleResi:
	mov	eax, edx
	lea	eax, DWORD PTR [edi+eax*2]
	mov	DWORD PTR tv2158[esp+128], eax
	mov	eax, DWORD PTR _src_row_size$[ebp]
	dec	eax
	lea	eax, DWORD PTR [edi+eax*2]
	cmp	DWORD PTR tv2154[esp+128], eax
	ja	SHORT $LN47@SimpleResi
	mov	ecx, DWORD PTR _src_row_size$[ebp]
	dec	ecx
	lea	eax, DWORD PTR [esi+ecx*2]
	mov	ecx, DWORD PTR _srcp2$1$[esp+128]
	cmp	eax, DWORD PTR tv2158[esp+128]
	jae	$LN45@SimpleResi
$LN47@SimpleResi:
	mov	eax, DWORD PTR tv2076[esp+128]
	and	eax, -2147483641			; 80000007H
	jns	SHORT $LN61@SimpleResi
	dec	eax
	or	eax, -8					; fffffff8H
	inc	eax
$LN61@SimpleResi:
	mov	edx, DWORD PTR _src_row_size$[ebp]
	movaps	xmm2, XMMWORD PTR __xmm@00000080000000800000008000000080
	mov	DWORD PTR tv2137[esp+128], edx

; 207  :     }
; 208  :     // the rest one-by-one
; 209  :     for (int x = mod8or16w; x < src_row_size; x++) {

	mov	edx, ecx
	sub	DWORD PTR tv2137[esp+128], eax
	sub	edx, edi
	mov	eax, 8
	mov	DWORD PTR tv2152[esp+128], edx
	mov	edx, esi
	sub	edx, edi
	mov	DWORD PTR tv2136[esp+128], edx
	movd	xmm3, eax
	mov	eax, DWORD PTR _mod8or16w$1$[esp+128]
	add	eax, 4
	sub	ecx, esi
	mov	esi, DWORD PTR tv2154[esp+128]
	mov	DWORD PTR tv2151[esp+128], ecx
	mov	ecx, edx
	lea	eax, DWORD PTR [edi+eax*2]
	mov	edi, DWORD PTR tv2152[esp+128]
	npad	1
$LL10@SimpleResi:
	mov	edx, DWORD PTR tv2151[esp+128]
	lea	esi, DWORD PTR [esi+16]
	lea	eax, DWORD PTR [eax+16]
	movq	xmm0, QWORD PTR [edx+esi-16]

; 210  :       vWorkYW[x] = (srcp1[x] * invCurrentWeight + srcp2[x] * CurrentWeight + 128) >> 8;

	pmovsxwd xmm1, xmm0
	movq	xmm0, QWORD PTR [eax-24]
	pmovsxwd xmm0, xmm0
	pmulld	xmm0, xmm5
	pmulld	xmm1, xmm4
	paddd	xmm1, xmm0
	mov	edx, DWORD PTR _x$1$[esp+128]
	paddd	xmm1, xmm2
	add	edx, 8
	psrad	xmm1, xmm3
	mov	DWORD PTR _x$1$[esp+128], edx
	pshuflw	xmm0, xmm1, 216				; 000000d8H
	pshufhw	xmm0, xmm0, 216				; 000000d8H
	pshufd	xmm0, xmm0, 216				; 000000d8H
	movq	QWORD PTR [esi-16], xmm0
	movq	xmm0, QWORD PTR [edi+eax-16]
	pmovsxwd xmm1, xmm0
	movq	xmm0, QWORD PTR [eax-16]
	pmovsxwd xmm0, xmm0
	pmulld	xmm0, xmm5
	pmulld	xmm1, xmm4
	paddd	xmm1, xmm0
	paddd	xmm1, xmm2
	psrad	xmm1, xmm3
	pshuflw	xmm0, xmm1, 216				; 000000d8H
	pshufhw	xmm0, xmm0, 216				; 000000d8H
	pshufd	xmm0, xmm0, 216				; 000000d8H
	movq	QWORD PTR [eax+ecx-16], xmm0
	cmp	edx, DWORD PTR tv2137[esp+128]
	jl	$LL10@SimpleResi
	mov	edi, DWORD PTR _srcp1$1$[esp+128]
	mov	ecx, DWORD PTR _srcp2$1$[esp+128]
	mov	esi, DWORD PTR _vWorkYW$1$[esp+128]
$LN45@SimpleResi:

; 207  :     }
; 208  :     // the rest one-by-one
; 209  :     for (int x = mod8or16w; x < src_row_size; x++) {

	cmp	edx, DWORD PTR _src_row_size$[ebp]
	jge	SHORT $LN9@SimpleResi
	sub	esi, ecx
	lea	edx, DWORD PTR [ecx+edx*2]
	mov	DWORD PTR tv2138[esp+128], esi
	sub	edi, ecx
	mov	esi, DWORD PTR _src_row_size$[ebp]
	sub	esi, DWORD PTR _x$1$[esp+128]
$LL44@SimpleResi:

; 210  :       vWorkYW[x] = (srcp1[x] * invCurrentWeight + srcp2[x] * CurrentWeight + 128) >> 8;

	movsx	ecx, WORD PTR [edx+edi]
	lea	edx, DWORD PTR [edx+2]
	imul	ecx, DWORD PTR _invCurrentWeight$1$[esp+128]
	movsx	eax, WORD PTR [edx-2]
	imul	eax, DWORD PTR _CurrentWeight$1$[esp+128]
	sub	ecx, -128				; ffffff80H
	add	eax, ecx
	mov	ecx, DWORD PTR tv2138[esp+128]
	sar	eax, 8
	mov	WORD PTR [edx+ecx-2], ax
	sub	esi, 1
	jne	SHORT $LL44@SimpleResi
	mov	esi, DWORD PTR _vWorkYW$1$[esp+128]
$LN9@SimpleResi:

; 218  :     for (int x = 0; x < row_size_mod4; x += 4) {

	mov	ecx, DWORD PTR _row_size_mod4$1$[esp+128]
	test	ecx, ecx
	jle	$LN12@SimpleResi

; 211  :     }
; 212  : 
; 213  :     // We've taken care of the vertical scaling, now do horizontal
; 214  :     // rework
; 215  :     // We've taken care of the vertical scaling, now do horizontal
; 216  :     // vvv for src_type char it can be loop by 8
; 217  :     int row_size_mod4 = row_size & ~3;

	mov	eax, DWORD PTR _dstp8$[ebp]
	mov	edi, -16				; fffffff0H
	mov	edx, DWORD PTR _row_size_mod4$1$[esp+128]
	mov	DWORD PTR tv2123[esp+128], eax
	dec	edx
	mov	eax, DWORD PTR _pControl$1$[esp+128]
	sub	edi, eax
	shr	edx, 2
	inc	edx
	lea	ecx, DWORD PTR [eax+16]
	npad	6
$LL13@SimpleResi:

; 219  : #ifdef USE_SSE2_HORIZONTAL_HELPERS        
; 220  :       unsigned int pc0, pc1, pc2, pc3;
; 221  :       short b0, b1, b2, b3, b4, b5, b6, b7;
; 222  : #endif
; 223  :       unsigned int offs0, offs1, offs2, offs3;
; 224  : 
; 225  :       // mov		eax, [rsi + 16]
; 226  :       offs0 = pControl[3 * x + 4];   // get data offset in pixels, 1st pixel pair. Control[4]=offs
; 227  :                                      // mov		ebx, [rsi + 20]
; 228  :       offs1 = pControl[3 * x + 5];   // get data offset in pixels, 2nd pixel pair. Control[5]=offsodd
; 229  : 
; 230  :       offs2 = pControl[3 * x + 4 + (2 * 3)];   // get data offset in pixels, 3nd pixel pair. Control[5]=offsodd
; 231  :       offs3 = pControl[3 * x + 5 + (2 * 3)];   // get data offset in pixels, 4nd pixel pair. Control[5]=offsodd
; 232  : 
; 233  :                                              /*source_t*/
; 234  :                                              // (uint32_t)pair1     = (uint32_t *)((short *)(vWorkYW)[offs])      // vWorkYW[offs] and vWorkYW[offs+1]
; 235  :                                              // (uint32_t)pair2odds = (uint32_t *)((short *)(vWorkYW)[offsodds])  // vWorkYW[offsodds] and vWorkYW[offsodds+1]
; 236  :       __m128i a_pair3210;
; 237  :       uint32_t pair0, pair1, pair2, pair3;
; 238  :       if (sizeof(workY_type) == 1) { // vWorkYW uchars
; 239  :         uint16_t pair0_2x8 = *(uint16_t *)(&vWorkYW[offs0]);      // vWorkYW[offs] and vWorkYW[offs+1]
; 240  :         uint16_t pair1_2x8 = *(uint16_t *)(&vWorkYW[offs1]);      // vWorkYW[offs] and vWorkYW[offs+1]
; 241  :         uint16_t pair2_2x8 = *(uint16_t *)(&vWorkYW[offs2]);      // vWorkYW[offs] and vWorkYW[offs+1]
; 242  :         uint16_t pair3_2x8 = *(uint16_t *)(&vWorkYW[offs3]);      // vWorkYW[offs] and vWorkYW[offs+1]
; 243  :         pair0 = (((uint32_t)pair0_2x8 & 0xFF00) << 8) + (pair0_2x8 & 0xFF);
; 244  :         pair1 = (((uint32_t)pair1_2x8 & 0xFF00) << 8) + (pair1_2x8 & 0xFF);
; 245  :         pair2 = (((uint32_t)pair2_2x8 & 0xFF00) << 8) + (pair2_2x8 & 0xFF);
; 246  :         pair3 = (((uint32_t)pair3_2x8 & 0xFF00) << 8) + (pair3_2x8 & 0xFF);
; 247  :         __m128i a_pair10 = _mm_or_si128(_mm_shuffle_epi32(_mm_cvtsi32_si128(pair1), _MM_SHUFFLE(0, 0, 0, 1)), _mm_cvtsi32_si128(pair0));
; 248  :         __m128i a_pair32 = _mm_or_si128(_mm_shuffle_epi32(_mm_cvtsi32_si128(pair3), _MM_SHUFFLE(0, 0, 0, 1)), _mm_cvtsi32_si128(pair2));
; 249  :         a_pair3210 = _mm_unpacklo_epi64(a_pair10, a_pair32);
; 250  : 
; 251  :       }
; 252  :       else { // vWorkYW shorts
; 253  :         pair0 = *(uint32_t *)(&vWorkYW[offs0]);      // vWorkYW[offs] and vWorkYW[offs+1]
; 254  :         pair1 = *(uint32_t *)(&vWorkYW[offs1]);      // vWorkYW[offs] and vWorkYW[offs+1]
; 255  :         pair2 = *(uint32_t *)(&vWorkYW[offs2]);      // vWorkYW[offs] and vWorkYW[offs+1]
; 256  :         pair3 = *(uint32_t *)(&vWorkYW[offs3]);      // vWorkYW[offs] and vWorkYW[offs+1]
; 257  :         __m128i a_pair10 = _mm_or_si128(_mm_shuffle_epi32(_mm_cvtsi32_si128(pair1), _MM_SHUFFLE(0, 0, 0, 1)), _mm_cvtsi32_si128(pair0));
; 258  :         __m128i a_pair32 = _mm_or_si128(_mm_shuffle_epi32(_mm_cvtsi32_si128(pair3), _MM_SHUFFLE(0, 0, 0, 1)), _mm_cvtsi32_si128(pair2));
; 259  :         a_pair3210 = _mm_unpacklo_epi64(a_pair10, a_pair32);
; 260  :       }
; 261  : 
; 262  : #ifdef USE_SSE2_HORIZONTAL_HELPERS        
; 263  :       pc0 = pControl[3 * x + 0];         // uint32: Y2_0:Y1_0
; 264  :       pc1 = pControl[3 * x + 1];         // uint32: Y2_1:Y1_1 
; 265  :       pc2 = pControl[3 * x + 0 + (2 * 3)]; // uint32: Y2_2:Y1_2 
; 266  :       pc3 = pControl[3 * x + 1 + (2 * 3)]; // uint32: Y2_3:Y1_3 
; 267  : #endif
; 268  : 
; 269  :       // pc1, pc0
; 270  :       __m128i b_pair10 = _mm_loadl_epi64(reinterpret_cast<const __m128i*>(&pControl[3 * x + 0])); // +0, +1
; 271  :       // load the lower 64 bits from (unaligned)
; 272  :       // pc3, pc2
; 273  :       __m128i b_pair3210 = _mm_castpd_si128(_mm_loadh_pd(_mm_castsi128_pd(b_pair10), reinterpret_cast<const double*>(&pControl[3 * x + 0 + (2 * 3)])));

	movq	xmm0, QWORD PTR [ecx-16]
	lea	eax, DWORD PTR [edi+ecx]
	mov	esi, DWORD PTR _pControl$1$[esp+128]
	lea	ecx, DWORD PTR [ecx+48]
	movq	xmm3, xmm0
	movhpd	xmm3, QWORD PTR [eax+esi+24]
	mov	eax, DWORD PTR [ecx-44]
	mov	esi, DWORD PTR _vWorkYW$1$[esp+128]
	movd	xmm0, DWORD PTR [esi+eax*2]
	mov	eax, DWORD PTR [ecx-48]
	pshufd	xmm2, xmm0, 1
	movd	xmm0, DWORD PTR [esi+eax*2]
	mov	eax, DWORD PTR [ecx-20]
	por	xmm2, xmm0
	movd	xmm0, DWORD PTR [esi+eax*2]
	mov	eax, DWORD PTR [ecx-24]
	pshufd	xmm1, xmm0, 1
	movd	xmm0, DWORD PTR [esi+eax*2]

; 274  :       // load the higher 64 bits from 2nd param, lower 64 bit copied from 1st param
; 275  : 
; 276  : #ifdef USE_SSE2_HORIZONTAL_HELPERS        
; 277  :       unsigned int wY1_0 = b0 = pc0 & 0x0000ffff; //low
; 278  :       unsigned int wY2_0 = b1 = pc0 >> 16; //high
; 279  :       unsigned int wY1_1 = b2 = pc1 & 0x0000ffff; //low
; 280  :       unsigned int wY2_1 = b3 = pc1 >> 16; //high
; 281  :       unsigned int wY1_2 = b4 = pc2 & 0x0000ffff; //low
; 282  :       unsigned int wY2_2 = b5 = pc2 >> 16; //high
; 283  :       unsigned int wY1_3 = b6 = pc3 & 0x0000ffff; //low
; 284  :       unsigned int wY2_3 = b7 = pc3 >> 16; //high
; 285  :       short a0 = vWorkYW[offs0]; // 1 or 2 byte
; 286  :       short a1 = vWorkYW[offs0 + 1];
; 287  :       short a2 = vWorkYW[offs1];
; 288  :       short a3 = vWorkYW[offs1 + 1];
; 289  :       short a4 = vWorkYW[offs2];
; 290  :       short a5 = vWorkYW[offs2 + 1];
; 291  :       short a6 = vWorkYW[offs3];
; 292  :       short a7 = vWorkYW[offs3 + 1];
; 293  : 
; 294  :       BYTE res0 = (a0 * b0 + a1 * b1 + 128) >> 8;
; 295  :       BYTE res1 = (a2 * b2 + a3 * b3 + 128) >> 8;
; 296  :       BYTE res2 = (a4 * b4 + a5 * b5 + 128) >> 8;
; 297  :       BYTE res3 = (a6 * b6 + a7 * b7 + 128) >> 8;
; 298  :       BYTE cmp0 = dstp[x + 0];
; 299  :       BYTE cmp1 = dstp[x + 1];
; 300  :       BYTE cmp2 = dstp[x + 2];
; 301  :       BYTE cmp3 = dstp[x + 3];
; 302  :       /*
; 303  :       dstp[x+0] = res0;
; 304  :       dstp[x+1] = res1;
; 305  :       dstp[x+2] = res2;
; 306  :       dstp[x+3] = res3;
; 307  :       */
; 308  : #endif
; 309  :       // pmaddwd mm0, [rsi]			// mult and sum lumas by ctl weights. v1v0 Control[1] and w1w0 Control[0]
; 310  :       // __m128i _mm_madd_epi16 (__m128i a, __m128i b);
; 311  :       // PMADDWD
; 312  :       // r0 := (a0 * b0) + (a1 * b1)
; 313  :       // r1 := (a2 * b2) + (a3 * b3)
; 314  :       // r2 := (a4 * b4) + (a5 * b5)
; 315  :       // r3 := (a6 * b6) + (a7 * b7)
; 316  :       __m128i result = _mm_madd_epi16(a_pair3210, b_pair3210); // 4x integer
; 317  :       __m128i rounder = _mm_set1_epi32(0x0080);
; 318  :       result = _mm_add_epi32(result, rounder);
; 319  : 
; 320  :       if (sizeof(src_type) == 1)
; 321  :         result = _mm_srli_epi32(result, 8);
; 322  :       else
; 323  :         result = _mm_srai_epi32(result, 8);  // 16 bit: arithmetic shift as in orig asm
; 324  :       result = _mm_packs_epi32(result, result); // 4xqword ->4xword
; 325  :       if (sizeof(src_type) == 1) {
; 326  :         // 8 bit version
; 327  :         result = _mm_packus_epi16(result, result); // 4xword ->4xbyte
; 328  :         uint32_t final4x8bitpixels = _mm_cvtsi128_si32(result);
; 329  :         *(uint32_t *)(&dstp[x]) = final4x8bitpixels;
; 330  :       }
; 331  :       else {
; 332  :         // for short version: 
; 333  :         _mm_storel_epi64(reinterpret_cast<__m128i *>(&dstp[x]), result);

	mov	eax, DWORD PTR tv2123[esp+128]
	por	xmm1, xmm0
	punpcklqdq xmm2, xmm1
	pmaddwd	xmm2, xmm3
	paddd	xmm2, XMMWORD PTR __xmm@00000080000000800000008000000080
	psrad	xmm2, 8
	packssdw xmm2, xmm2
	movq	QWORD PTR [eax], xmm2
	add	eax, 8
	mov	DWORD PTR tv2123[esp+128], eax
	sub	edx, 1
	jne	SHORT $LL13@SimpleResi
	mov	ecx, DWORD PTR _row_size_mod4$1$[esp+128]
$LN12@SimpleResi:

; 334  :       }
; 335  :     }
; 336  :     // remaining
; 337  :     for (int x = row_size_mod4; x < row_size; x++) {

	mov	edx, ecx
	mov	DWORD PTR _x$1$[esp+128], edx
	cmp	ecx, DWORD PTR _row_size$[ebp]
	jge	SHORT $LN15@SimpleResi
	lea	eax, DWORD PTR [ecx+ecx*2]
	mov	ecx, DWORD PTR _pControl$1$[esp+128]
	lea	eax, DWORD PTR [eax-2]
	lea	eax, DWORD PTR [ecx+eax*4]
$LL16@SimpleResi:

; 338  :       unsigned int pc;
; 339  :       unsigned int offs;
; 340  : 
; 341  :       if ((x & 1) == 0) { // even

	test	dl, 1
	jne	SHORT $LN27@SimpleResi

; 342  :         pc = pControl[3 * x];

	mov	edx, DWORD PTR [eax+8]

; 343  :         offs = pControl[3 * x + 4];

	mov	edi, DWORD PTR [eax+24]

; 344  :       }
; 345  :       else { // odd

	jmp	SHORT $LN28@SimpleResi
$LN27@SimpleResi:

; 346  :         pc = pControl[3 * x - 2]; // [3*xeven+1]

	mov	edx, DWORD PTR [eax]

; 347  :         offs = pControl[3 * x + 2]; // [3*xeven+5]

	mov	edi, DWORD PTR [eax+16]
$LN28@SimpleResi:

; 348  :       }
; 349  :       unsigned int wY1 = pc & 0x0000ffff; //low
; 350  :       unsigned int wY2 = pc >> 16; //high
; 351  :       dstp[x] = (vWorkYW[offs] * wY1 + vWorkYW[offs + 1] * wY2 + 128) >> 8;

	movsx	esi, WORD PTR [esi+edi*2+2]
	mov	ecx, edx
	shr	ecx, 16					; 00000010H
	add	eax, 12					; 0000000cH
	imul	esi, ecx
	mov	ecx, DWORD PTR _vWorkYW$1$[esp+128]
	movzx	edx, dx
	movsx	ecx, WORD PTR [ecx+edi*2]
	sub	esi, -128				; ffffff80H
	imul	ecx, edx
	mov	edx, DWORD PTR _x$1$[esp+128]
	add	ecx, esi
	mov	esi, DWORD PTR _dstp8$[ebp]
	shr	ecx, 8
	mov	WORD PTR [esi+edx*2], cx
	inc	edx
	mov	esi, DWORD PTR _vWorkYW$1$[esp+128]
	mov	DWORD PTR _x$1$[esp+128], edx
	cmp	edx, DWORD PTR _row_size$[ebp]
	jl	SHORT $LL16@SimpleResi
$LN15@SimpleResi:

; 140  : 
; 141  :   for (int y = 0; y < height; y++)

	mov	ecx, DWORD PTR _y$1$[esp+128]
	mov	edi, DWORD PTR _vOffsetsW$1$[esp+128]
	inc	ecx

; 352  :     }
; 353  :     // rework end
; 354  : 
; 355  :     dstp += dst_pitch;

	mov	eax, DWORD PTR tv2164[esp+128]
	add	edi, 4
	add	DWORD PTR _dstp8$[ebp], eax
	mov	esi, DWORD PTR _vWorkYW$1$[esp+128]
	mov	eax, DWORD PTR _vWeightsW$1$[esp+128]
	mov	DWORD PTR _y$1$[esp+128], ecx
	mov	DWORD PTR _vOffsetsW$1$[esp+128], edi
	cmp	ecx, DWORD PTR _height$[ebp]
	jl	$LL4@SimpleResi
$LN3@SimpleResi:

; 356  : 
; 357  :   } // for y
; 358  : }

	pop	edi
	pop	esi
	mov	esp, ebp
	pop	ebp
	ret	28					; 0000001cH
??$SimpleResizeDo_New@F@SimpleResize@@QAEXPAEHHHPBEHH@Z ENDP ; SimpleResize::SimpleResizeDo_New<short>
_TEXT	ENDS
END
